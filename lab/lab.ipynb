{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.ndarray(shape=(2, 2), dtype=float, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1[0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 1.64029794e-321],\n",
       "       [1.12465777e-311, 3.79442416e-321]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0692, -0.3354, -1.2829,  2.0761, -1.8108, -0.6966],\n",
       "        [-1.5984, -1.3291, -0.2539, -0.0140, -0.6173,  0.0661]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.randn(2,6)\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 10]) torch.Size([3, 3, 10])\n",
      "GRU(6, 10, num_layers=3)\n"
     ]
    }
   ],
   "source": [
    "GRU = torch.nn.GRU(6, 10, 3) # input_size, hidden_size, num_layers \n",
    "input_data = torch.randn(5, 3, 6)\n",
    "h0 = torch.randn(3, 3, 10) #h0 is the initial hidden state of the GRU, which is a tensor of shape (num_layers * num_directions, batch, hidden_size)\n",
    "#batch is the number of samples in a batch, hidden_size is the number of hidden units in the GRU cell, and num_layers is the number of layers in the GRU cell.\n",
    "output, hn = GRU(input_data, h0)\n",
    "\n",
    "print(output.size(), hn.size())\n",
    "print(GRU)#GRU(6, 10, num_layers=2) means that the input size is 6, the hidden size is 10, and the number of layers is 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchsummary is used to print the model summary -> model must be object of nn.Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 10, 1]              11\n",
      "================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: hibana2077 hibana2077@gmail.com\n",
    "Date: 2022-12-25 13:20:07\n",
    "LastEditors: hibana2077 hibana2077@gmail.com\n",
    "LastEditTime: 2022-12-28 00:17:46\n",
    "FilePath: \\OOP-independent-study\\lab\\lab.ipynb\n",
    "Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE\n",
    "'''\n",
    "#double LSTM model\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "class simple_liner_reg(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_liner_reg, self).__init__()\n",
    "        self.linear = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "model = simple_liner_reg()\n",
    "summary(model, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class more_complex_liner_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(more_complex_liner_model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(1, 10) # 10 input features, 10 output features (for example)\n",
    "        self.linear2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(10, 256)\n",
    "        self.linear4 = torch.nn.Sigmoid()\n",
    "        self.linear5 = torch.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear1(x)\n",
    "        y_pred = self.linear2(y_pred)\n",
    "        y_pred = self.linear3(y_pred)\n",
    "        y_pred = self.linear4(y_pred)\n",
    "        y_pred = self.linear5(y_pred)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = lambda x: x**2 + 2*x + 1\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "y = problem(x)\n",
    "\n",
    "#reshape\n",
    "x = x.view(5, 1)\n",
    "y = y.view(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 445.9723815917969\n",
      "199 321.51177978515625\n",
      "299 215.24900817871094\n",
      "399 131.79396057128906\n",
      "499 77.84037017822266\n",
      "599 49.662925720214844\n",
      "699 35.14437484741211\n",
      "799 25.83038330078125\n",
      "899 19.269283294677734\n",
      "999 15.046280860900879\n",
      "1099 12.149673461914062\n",
      "1199 10.052809715270996\n",
      "1299 8.466920852661133\n",
      "1399 7.18192195892334\n",
      "1499 6.137800216674805\n",
      "1599 5.339715003967285\n",
      "1699 4.713237762451172\n",
      "1799 4.214264869689941\n",
      "1899 3.929901599884033\n",
      "1999 3.7299396991729736\n",
      "2099 3.5528464317321777\n",
      "2199 3.3898510932922363\n",
      "2299 3.2382845878601074\n",
      "2399 3.0966506004333496\n",
      "2499 2.963745594024658\n",
      "2599 2.8386731147766113\n",
      "2699 2.72057843208313\n",
      "2799 2.608788251876831\n",
      "2899 2.5027289390563965\n",
      "2999 2.40189790725708\n",
      "3099 2.3058676719665527\n",
      "3199 2.214247703552246\n",
      "3299 2.1267242431640625\n",
      "3399 2.043006420135498\n",
      "3499 1.9628480672836304\n",
      "3599 1.8860158920288086\n",
      "3699 1.8123347759246826\n",
      "3799 1.7415870428085327\n",
      "3899 1.6736607551574707\n",
      "3999 1.6083862781524658\n",
      "4099 1.5456328392028809\n",
      "4199 1.4852643013000488\n",
      "4299 1.4272053241729736\n",
      "4399 1.3713531494140625\n",
      "4499 1.3175735473632812\n",
      "4599 1.2658194303512573\n",
      "4699 1.2159968614578247\n",
      "4799 1.1680296659469604\n",
      "4899 1.121841311454773\n",
      "4999 1.0773704051971436\n",
      "5099 1.0345613956451416\n",
      "5199 0.9933489561080933\n",
      "5299 0.953658401966095\n",
      "5399 0.9154510498046875\n",
      "5499 0.8786795139312744\n",
      "5599 0.8432732820510864\n",
      "5699 0.809203028678894\n",
      "5799 0.7764219641685486\n",
      "5899 0.7448740601539612\n",
      "5999 0.7145197987556458\n",
      "6099 0.6853154301643372\n",
      "6199 0.6572319269180298\n",
      "6299 0.6302226781845093\n",
      "6399 0.6042372584342957\n",
      "6499 0.5792633891105652\n",
      "6599 0.5552610754966736\n",
      "6699 0.5321868658065796\n",
      "6799 0.5100046396255493\n",
      "6899 0.48869588971138\n",
      "6999 0.4682193100452423\n",
      "7099 0.44855615496635437\n",
      "7199 0.4296661913394928\n",
      "7299 0.4115247130393982\n",
      "7399 0.3941114544868469\n",
      "7499 0.3773879408836365\n",
      "7599 0.3613356053829193\n",
      "7699 0.3459315896034241\n",
      "7799 0.3311556279659271\n",
      "7899 0.3169751763343811\n",
      "7999 0.3033711314201355\n",
      "8099 0.29031768441200256\n",
      "8199 0.2778070271015167\n",
      "8299 0.26580315828323364\n",
      "8399 0.2542925179004669\n",
      "8499 0.24326279759407043\n",
      "8599 0.23269402980804443\n",
      "8699 0.22256040573120117\n",
      "8799 0.21284738183021545\n",
      "8899 0.20354631543159485\n",
      "8999 0.19463711977005005\n",
      "9099 0.18609385192394257\n",
      "9199 0.1779179573059082\n",
      "9299 0.17008285224437714\n",
      "9399 0.16258566081523895\n",
      "9499 0.155403733253479\n",
      "9599 0.14852982759475708\n",
      "9699 0.1419496238231659\n",
      "9799 0.13564874231815338\n",
      "9899 0.12962183356285095\n",
      "9999 0.1238558292388916\n",
      "10099 0.11833358556032181\n",
      "10199 0.11305142194032669\n",
      "10299 0.10799966752529144\n",
      "10399 0.10316676646471024\n",
      "10499 0.09854386746883392\n",
      "10599 0.09412509948015213\n",
      "10699 0.0898968055844307\n",
      "10799 0.08585238456726074\n",
      "10899 0.08198785036802292\n",
      "10999 0.07829305529594421\n",
      "11099 0.07475768774747849\n",
      "11199 0.0713803619146347\n",
      "11299 0.06815177947282791\n",
      "11399 0.0650649219751358\n",
      "11499 0.06211695447564125\n",
      "11599 0.059297624975442886\n",
      "11699 0.05660618841648102\n",
      "11799 0.054033081978559494\n",
      "11899 0.051573485136032104\n",
      "11999 0.04922529309988022\n",
      "12099 0.046984534710645676\n",
      "12199 0.04483918845653534\n",
      "12299 0.04279112443327904\n",
      "12399 0.04083621874451637\n",
      "12499 0.038968849927186966\n",
      "12599 0.03718477115035057\n",
      "12699 0.03548206388950348\n",
      "12799 0.033855754882097244\n",
      "12899 0.03230220079421997\n",
      "12999 0.030820831656455994\n",
      "13099 0.029404062777757645\n",
      "13199 0.02805284969508648\n",
      "13299 0.02676253765821457\n",
      "13399 0.02553028054535389\n",
      "13499 0.02435540221631527\n",
      "13599 0.023233041167259216\n",
      "13699 0.022161148488521576\n",
      "13799 0.021137915551662445\n",
      "13899 0.02016189694404602\n",
      "13999 0.019231418147683144\n",
      "14099 0.018342817202210426\n",
      "14199 0.01749468222260475\n",
      "14299 0.016685351729393005\n",
      "14399 0.015912391245365143\n",
      "14499 0.015175580978393555\n",
      "14599 0.014471628703176975\n",
      "14699 0.013801735825836658\n",
      "14799 0.013161655515432358\n",
      "14899 0.012550683692097664\n",
      "14999 0.011968061327934265\n",
      "15099 0.01141195185482502\n",
      "15199 0.010882487520575523\n",
      "15299 0.010376709513366222\n",
      "15399 0.009894168004393578\n",
      "15499 0.009433801285922527\n",
      "15599 0.00899429339915514\n",
      "15699 0.008576621301472187\n",
      "15799 0.008177118375897408\n",
      "15899 0.007795903831720352\n",
      "15999 0.007432836107909679\n",
      "16099 0.007086390629410744\n",
      "16199 0.006756136193871498\n",
      "16299 0.006441343575716019\n",
      "16399 0.006140362471342087\n",
      "16499 0.005853885319083929\n",
      "16599 0.005580495111644268\n",
      "16699 0.005320271942764521\n",
      "16799 0.005071850493550301\n",
      "16899 0.004834687802940607\n",
      "16999 0.004608588758856058\n",
      "17099 0.004393020644783974\n",
      "17199 0.004187909886240959\n",
      "17299 0.003992257174104452\n",
      "17399 0.003805108368396759\n",
      "17499 0.0036268047988414764\n",
      "17599 0.003457123413681984\n",
      "17699 0.00329575571231544\n",
      "17799 0.003141466062515974\n",
      "17899 0.002994321286678314\n",
      "17999 0.002853688783943653\n",
      "18099 0.002720070304349065\n",
      "18199 0.0025927729438990355\n",
      "18299 0.0024712656158953905\n",
      "18399 0.0023553655482828617\n",
      "18499 0.002244844799861312\n",
      "18599 0.002139795571565628\n",
      "18699 0.002038904931396246\n",
      "18799 0.001943313516676426\n",
      "18899 0.0018520242301747203\n",
      "18999 0.0017657806165516376\n",
      "19099 0.0016826663631945848\n",
      "19199 0.0016036592423915863\n",
      "19299 0.0015283302636817098\n",
      "19399 0.0014567250618711114\n",
      "19499 0.0013881610939279199\n",
      "19599 0.0013228909811004996\n",
      "19699 0.001260488061234355\n",
      "19799 0.0012015027459710836\n",
      "19899 0.0011450813617557287\n",
      "19999 0.0010913427686318755\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, loss_fn, optimizer, x, y, epochs=20000):\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 99:\n",
    "            print(epoch, loss.item())\n",
    "\n",
    "model = more_complex_liner_model()\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "train_model(model, loss_fn, optimizer, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(5) true: 36 , f(5) pred: 35.984130859375\n"
     ]
    }
   ],
   "source": [
    "print(f\"f(5) true: {problem(5)} , f(5) pred: {model(torch.tensor([5.0])).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(6) true: 49 , f(6) pred: 45.06508255004883\n"
     ]
    }
   ],
   "source": [
    "print(f\"f(6) true: {problem(6)} , f(6) pred: {model(torch.tensor([6.0])).item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
