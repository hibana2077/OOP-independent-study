{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6epq6_O1vvia"
      },
      "source": [
        "[![GitHub](https://img.shields.io/badge/Github-hibana2077-blue?style=plastic-square&logo=github)](https://github.com/hibana2077)\n",
        "[![Colab](https://img.shields.io/badge/Colab-Open%20in%20Colab-blue?style=plastic-square&logo=googlecolab)](https://colab.research.google.com/github/hibana2077/hibana2077/blob/master/train/train.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t38eQJt0vvid"
      },
      "source": [
        "如果要訓練這份資料集會需要安裝talib套件，請參考[這裡](https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib)下載對應的版本，並使用pip安裝。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWr_Ksvyv3Ro",
        "outputId": "a1ee08c2-55e0-4e05-a5e3-39430fde8c45"
      },
      "outputs": [],
      "source": [
        "# !pip install ccxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSuyiZlLwOO5",
        "outputId": "3d1ec1a2-6001-4306-8424-1923934b2884"
      },
      "outputs": [],
      "source": [
        "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "# !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "# %cd ta-lib\n",
        "# !./configure --prefix=/usr\n",
        "# !make\n",
        "# !make install\n",
        "# !pip install Ta-Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "0dEqkDzevvie",
        "outputId": "4ef1a61d-0ce2-40b5-8102-d6a51827ef87"
      },
      "outputs": [],
      "source": [
        "from ccxt import binance\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from talib import abstract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H59nhzEFvvif"
      },
      "source": [
        "# 環境整理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zjpnlfgcvvif"
      },
      "outputs": [],
      "source": [
        "ls_dir = os.listdir(path=\"..\")\n",
        "if \"data\" not in ls_dir:\n",
        "    os.mkdir(path=\"../data\")\n",
        "if \"model\" not in ls_dir:\n",
        "    os.mkdir(path=\"../model\")\n",
        "if \"data\" in ls_dir:\n",
        "    ls_dir = os.listdir(path=\"../data\")\n",
        "    #remove all files in data folder\n",
        "    for file in ls_dir:os.remove(path=\"../data/\"+file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG1FGxMUvvig"
      },
      "source": [
        "# 下載資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "29klRj8yvvig"
      },
      "outputs": [],
      "source": [
        "# Binance BTC/USDT 1h candles from 2020-01-01 to 2021-01-01\n",
        "\n",
        "binance = binance()\n",
        "symbol = 'ADA/USDT'\n",
        "timeframe = '15m'\n",
        "file_name = f\"../data/{symbol.replace('/', '_')}_{timeframe}.csv\"\n",
        "start = binance.parse8601('2022-10-01T00:00:00Z')\n",
        "end = binance.parse8601('2022-12-30T00:00:00Z')\n",
        "cnt_time = start\n",
        "data = []\n",
        "while cnt_time < end:\n",
        "    ohlcv = binance.fetch_ohlcv(symbol, timeframe, cnt_time)\n",
        "    data += ohlcv\n",
        "    cnt_time = ohlcv[-1][0] + 3600000 # 1h in ms    \n",
        "df = pd.DataFrame(data, columns=['time', 'open', 'high', 'low', 'close', 'volume'])\n",
        "df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
        "df.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhcDY9sbvvih"
      },
      "source": [
        "# 讀取資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT6TVXPQvvih"
      },
      "outputs": [],
      "source": [
        "#如果有下载好的數據，可以直接讀取\n",
        "data_file = '../data/btc_usdt_1h.csv' #-> 可以自行更換\n",
        "df = pd.read_csv(data_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz939phEvvih"
      },
      "source": [
        "# 數據處理\n",
        "\n",
        "- 計算RSI\n",
        "- 計算MACD\n",
        "- 計算OBV\n",
        "- 計算CCI\n",
        "- 改成變化百分比 -> 標準化\n",
        "\n",
        "關於技術指標的說明可以參考[這裡](https://www.investopedia.com/terms/t/technicalindicator.asp)，或是google。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cWEqDOiVvvih"
      },
      "outputs": [],
      "source": [
        "df['RSI'] = abstract.RSI(df, timeperiod=14)\n",
        "df['MACD'] = abstract.MACD(df, fastperiod=12, slowperiod=26, signalperiod=9)['macd'] #只取MACD\n",
        "df['OBV'] = abstract.OBV(df, timeperiod=14)\n",
        "df['CCI'] = abstract.CCI(df, timeperiod=14)\n",
        "df['ATR'] = abstract.ATR(df, timeperiod=14)\n",
        "df['ADX'] = abstract.ADX(df, timeperiod=14)\n",
        "df['MFI'] = abstract.MFI(df, timeperiod=14)\n",
        "df['CLOSE_percent'] = df['close'].pct_change()\n",
        "#由於RSI MACD OBV CCI 他們已經是標準化的，所以不需要再標準化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDPm_zt2vvii"
      },
      "source": [
        "# 設定買賣點\n",
        "\n",
        "將買賣點分為下跌、上漲、不動，並將數據轉成one-hot編碼。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kQ0vSu6Yvvii"
      },
      "outputs": [],
      "source": [
        "df['UP'] = df['CLOSE_percent'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df['DOWN'] = df['CLOSE_percent'].apply(lambda x: 1 if x < 0 else 0)\n",
        "df['UP'] = df['UP'].shift(-1) #shift UP DOWN 一個單位，因為我們要預測的是下一個時間點的漲跌\n",
        "df['DOWN'] = df['DOWN'].shift(-1)\n",
        "\n",
        "df = df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k77OIN-dvvii"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>OBV</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>ADX</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CLOSE_percent</th>\n",
              "      <th>UP</th>\n",
              "      <th>DOWN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-10-01 08:15:00</td>\n",
              "      <td>8397.80</td>\n",
              "      <td>8399.84</td>\n",
              "      <td>8355.00</td>\n",
              "      <td>8356.53</td>\n",
              "      <td>383.065769</td>\n",
              "      <td>49.371020</td>\n",
              "      <td>22.323754</td>\n",
              "      <td>3364.579414</td>\n",
              "      <td>-70.616834</td>\n",
              "      <td>39.812174</td>\n",
              "      <td>29.333975</td>\n",
              "      <td>23.902832</td>\n",
              "      <td>-0.004912</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-10-01 08:30:00</td>\n",
              "      <td>8357.33</td>\n",
              "      <td>8375.29</td>\n",
              "      <td>8345.00</td>\n",
              "      <td>8366.91</td>\n",
              "      <td>476.302794</td>\n",
              "      <td>51.246753</td>\n",
              "      <td>18.889651</td>\n",
              "      <td>3840.882208</td>\n",
              "      <td>-86.262910</td>\n",
              "      <td>39.132018</td>\n",
              "      <td>27.373650</td>\n",
              "      <td>17.775859</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-10-01 08:45:00</td>\n",
              "      <td>8366.57</td>\n",
              "      <td>8381.38</td>\n",
              "      <td>8363.79</td>\n",
              "      <td>8376.28</td>\n",
              "      <td>235.717562</td>\n",
              "      <td>52.941620</td>\n",
              "      <td>16.731313</td>\n",
              "      <td>4076.599770</td>\n",
              "      <td>-40.451685</td>\n",
              "      <td>37.593303</td>\n",
              "      <td>25.482399</td>\n",
              "      <td>23.351751</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-10-01 09:00:00</td>\n",
              "      <td>8377.68</td>\n",
              "      <td>8378.41</td>\n",
              "      <td>8290.00</td>\n",
              "      <td>8319.34</td>\n",
              "      <td>710.028749</td>\n",
              "      <td>43.129386</td>\n",
              "      <td>10.307414</td>\n",
              "      <td>3366.571021</td>\n",
              "      <td>-191.047624</td>\n",
              "      <td>41.223067</td>\n",
              "      <td>25.493180</td>\n",
              "      <td>21.364349</td>\n",
              "      <td>-0.006798</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-10-01 09:15:00</td>\n",
              "      <td>8320.00</td>\n",
              "      <td>8330.04</td>\n",
              "      <td>8290.00</td>\n",
              "      <td>8305.68</td>\n",
              "      <td>613.360759</td>\n",
              "      <td>41.158558</td>\n",
              "      <td>4.067295</td>\n",
              "      <td>2753.210262</td>\n",
              "      <td>-226.560909</td>\n",
              "      <td>41.138562</td>\n",
              "      <td>25.503190</td>\n",
              "      <td>15.454057</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113243</th>\n",
              "      <td>2023-01-01 09:30:00</td>\n",
              "      <td>16514.64</td>\n",
              "      <td>16533.12</td>\n",
              "      <td>16514.22</td>\n",
              "      <td>16531.85</td>\n",
              "      <td>883.551270</td>\n",
              "      <td>52.745660</td>\n",
              "      <td>-4.536439</td>\n",
              "      <td>-56979.621176</td>\n",
              "      <td>9.296856</td>\n",
              "      <td>15.283688</td>\n",
              "      <td>31.376614</td>\n",
              "      <td>32.260504</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113244</th>\n",
              "      <td>2023-01-01 09:45:00</td>\n",
              "      <td>16531.85</td>\n",
              "      <td>16542.49</td>\n",
              "      <td>16525.62</td>\n",
              "      <td>16537.88</td>\n",
              "      <td>1213.731820</td>\n",
              "      <td>55.918864</td>\n",
              "      <td>-2.963106</td>\n",
              "      <td>-55765.889356</td>\n",
              "      <td>86.704775</td>\n",
              "      <td>15.396996</td>\n",
              "      <td>29.232544</td>\n",
              "      <td>33.333444</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113245</th>\n",
              "      <td>2023-01-01 10:00:00</td>\n",
              "      <td>16538.32</td>\n",
              "      <td>16543.14</td>\n",
              "      <td>16533.42</td>\n",
              "      <td>16542.85</td>\n",
              "      <td>1179.055140</td>\n",
              "      <td>58.398506</td>\n",
              "      <td>-1.300204</td>\n",
              "      <td>-54586.834216</td>\n",
              "      <td>128.445049</td>\n",
              "      <td>14.991496</td>\n",
              "      <td>27.181290</td>\n",
              "      <td>39.936794</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113246</th>\n",
              "      <td>2023-01-01 10:15:00</td>\n",
              "      <td>16542.60</td>\n",
              "      <td>16547.38</td>\n",
              "      <td>16539.98</td>\n",
              "      <td>16544.07</td>\n",
              "      <td>801.487390</td>\n",
              "      <td>59.008075</td>\n",
              "      <td>0.114779</td>\n",
              "      <td>-53785.346826</td>\n",
              "      <td>157.054176</td>\n",
              "      <td>14.449247</td>\n",
              "      <td>25.600024</td>\n",
              "      <td>44.888346</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113247</th>\n",
              "      <td>2023-01-01 10:30:00</td>\n",
              "      <td>16543.69</td>\n",
              "      <td>16544.75</td>\n",
              "      <td>16533.79</td>\n",
              "      <td>16539.58</td>\n",
              "      <td>970.788020</td>\n",
              "      <td>55.769305</td>\n",
              "      <td>0.863899</td>\n",
              "      <td>-54756.134846</td>\n",
              "      <td>109.511838</td>\n",
              "      <td>14.200015</td>\n",
              "      <td>24.011367</td>\n",
              "      <td>46.389703</td>\n",
              "      <td>-0.000271</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113215 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      time      open      high       low     close  \\\n",
              "33     2019-10-01 08:15:00   8397.80   8399.84   8355.00   8356.53   \n",
              "34     2019-10-01 08:30:00   8357.33   8375.29   8345.00   8366.91   \n",
              "35     2019-10-01 08:45:00   8366.57   8381.38   8363.79   8376.28   \n",
              "36     2019-10-01 09:00:00   8377.68   8378.41   8290.00   8319.34   \n",
              "37     2019-10-01 09:15:00   8320.00   8330.04   8290.00   8305.68   \n",
              "...                    ...       ...       ...       ...       ...   \n",
              "113243 2023-01-01 09:30:00  16514.64  16533.12  16514.22  16531.85   \n",
              "113244 2023-01-01 09:45:00  16531.85  16542.49  16525.62  16537.88   \n",
              "113245 2023-01-01 10:00:00  16538.32  16543.14  16533.42  16542.85   \n",
              "113246 2023-01-01 10:15:00  16542.60  16547.38  16539.98  16544.07   \n",
              "113247 2023-01-01 10:30:00  16543.69  16544.75  16533.79  16539.58   \n",
              "\n",
              "             volume        RSI       MACD           OBV         CCI  \\\n",
              "33       383.065769  49.371020  22.323754   3364.579414  -70.616834   \n",
              "34       476.302794  51.246753  18.889651   3840.882208  -86.262910   \n",
              "35       235.717562  52.941620  16.731313   4076.599770  -40.451685   \n",
              "36       710.028749  43.129386  10.307414   3366.571021 -191.047624   \n",
              "37       613.360759  41.158558   4.067295   2753.210262 -226.560909   \n",
              "...             ...        ...        ...           ...         ...   \n",
              "113243   883.551270  52.745660  -4.536439 -56979.621176    9.296856   \n",
              "113244  1213.731820  55.918864  -2.963106 -55765.889356   86.704775   \n",
              "113245  1179.055140  58.398506  -1.300204 -54586.834216  128.445049   \n",
              "113246   801.487390  59.008075   0.114779 -53785.346826  157.054176   \n",
              "113247   970.788020  55.769305   0.863899 -54756.134846  109.511838   \n",
              "\n",
              "              ATR        ADX        MFI  CLOSE_percent   UP  DOWN  \n",
              "33      39.812174  29.333975  23.902832      -0.004912  1.0   0.0  \n",
              "34      39.132018  27.373650  17.775859       0.001242  1.0   0.0  \n",
              "35      37.593303  25.482399  23.351751       0.001120  0.0   1.0  \n",
              "36      41.223067  25.493180  21.364349      -0.006798  0.0   1.0  \n",
              "37      41.138562  25.503190  15.454057      -0.001642  1.0   0.0  \n",
              "...           ...        ...        ...            ...  ...   ...  \n",
              "113243  15.283688  31.376614  32.260504       0.001067  1.0   0.0  \n",
              "113244  15.396996  29.232544  33.333444       0.000365  1.0   0.0  \n",
              "113245  14.991496  27.181290  39.936794       0.000301  1.0   0.0  \n",
              "113246  14.449247  25.600024  44.888346       0.000074  0.0   1.0  \n",
              "113247  14.200015  24.011367  46.389703      -0.000271  1.0   0.0  \n",
              "\n",
              "[113215 rows x 16 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aTh7CyL-vvij"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['RSI'] = (df['RSI'] - df['RSI'].min()) / (df['RSI'].max() - df['RSI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['MACD'] = (df['MACD'] - df['MACD'].min()) / (df['MACD'].max() - df['MACD'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['OBV'] = (df['OBV'] - df['OBV'].min()) / (df['OBV'].max() - df['OBV'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CCI'] = (df['CCI'] - df['CCI'].min()) / (df['CCI'].max() - df['CCI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ATR'] = (df['ATR'] - df['ATR'].min()) / (df['ATR'].max() - df['ATR'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ADX'] = (df['ADX'] - df['ADX'].min()) / (df['ADX'].max() - df['ADX'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['MFI'] = (df['MFI'] - df['MFI'].min()) / (df['MFI'].max() - df['MFI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['open'] = (df['open'] - df['open'].min()) / (df['open'].max() - df['open'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['high'] = (df['high'] - df['high'].min()) / (df['high'].max() - df['high'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['low'] = (df['low'] - df['low'].min()) / (df['low'].max() - df['low'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['close'] = (df['close'] - df['close'].min()) / (df['close'].max() - df['close'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_23024\\1144569331.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['volume'] = (df['volume'] - df['volume'].min()) / (df['volume'].max() - df['volume'].min())\n"
          ]
        }
      ],
      "source": [
        "#正規化\n",
        "df['RSI'] = (df['RSI'] - df['RSI'].min()) / (df['RSI'].max() - df['RSI'].min())\n",
        "df['MACD'] = (df['MACD'] - df['MACD'].min()) / (df['MACD'].max() - df['MACD'].min())\n",
        "df['OBV'] = (df['OBV'] - df['OBV'].min()) / (df['OBV'].max() - df['OBV'].min())\n",
        "df['CCI'] = (df['CCI'] - df['CCI'].min()) / (df['CCI'].max() - df['CCI'].min())\n",
        "df['ATR'] = (df['ATR'] - df['ATR'].min()) / (df['ATR'].max() - df['ATR'].min())\n",
        "df['ADX'] = (df['ADX'] - df['ADX'].min()) / (df['ADX'].max() - df['ADX'].min())\n",
        "df['MFI'] = (df['MFI'] - df['MFI'].min()) / (df['MFI'].max() - df['MFI'].min())\n",
        "df['open'] = (df['open'] - df['open'].min()) / (df['open'].max() - df['open'].min())\n",
        "df['high'] = (df['high'] - df['high'].min()) / (df['high'].max() - df['high'].min())\n",
        "df['low'] = (df['low'] - df['low'].min()) / (df['low'].max() - df['low'].min())\n",
        "df['close'] = (df['close'] - df['close'].min()) / (df['close'].max() - df['close'].min())\n",
        "df['volume'] = (df['volume'] - df['volume'].min()) / (df['volume'].max() - df['volume'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\李軒豪\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "df.drop(['CLOSE_percent'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UYO1j5O-vvij"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>OBV</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>ADX</th>\n",
              "      <th>MFI</th>\n",
              "      <th>UP</th>\n",
              "      <th>DOWN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-10-01 08:15:00</td>\n",
              "      <td>0.069553</td>\n",
              "      <td>0.064224</td>\n",
              "      <td>0.070680</td>\n",
              "      <td>0.069009</td>\n",
              "      <td>0.009489</td>\n",
              "      <td>0.494393</td>\n",
              "      <td>0.589019</td>\n",
              "      <td>0.356367</td>\n",
              "      <td>0.424339</td>\n",
              "      <td>0.017151</td>\n",
              "      <td>0.332065</td>\n",
              "      <td>0.239028</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-10-01 08:30:00</td>\n",
              "      <td>0.068929</td>\n",
              "      <td>0.063845</td>\n",
              "      <td>0.070526</td>\n",
              "      <td>0.069169</td>\n",
              "      <td>0.011798</td>\n",
              "      <td>0.514935</td>\n",
              "      <td>0.587832</td>\n",
              "      <td>0.357083</td>\n",
              "      <td>0.407575</td>\n",
              "      <td>0.016798</td>\n",
              "      <td>0.304525</td>\n",
              "      <td>0.177759</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-10-01 08:45:00</td>\n",
              "      <td>0.069071</td>\n",
              "      <td>0.063939</td>\n",
              "      <td>0.070816</td>\n",
              "      <td>0.069314</td>\n",
              "      <td>0.005839</td>\n",
              "      <td>0.533497</td>\n",
              "      <td>0.587086</td>\n",
              "      <td>0.357438</td>\n",
              "      <td>0.456659</td>\n",
              "      <td>0.016002</td>\n",
              "      <td>0.277955</td>\n",
              "      <td>0.233518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-10-01 09:00:00</td>\n",
              "      <td>0.069243</td>\n",
              "      <td>0.063893</td>\n",
              "      <td>0.069676</td>\n",
              "      <td>0.068435</td>\n",
              "      <td>0.017587</td>\n",
              "      <td>0.426038</td>\n",
              "      <td>0.584865</td>\n",
              "      <td>0.356370</td>\n",
              "      <td>0.295306</td>\n",
              "      <td>0.017881</td>\n",
              "      <td>0.278106</td>\n",
              "      <td>0.213643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-10-01 09:15:00</td>\n",
              "      <td>0.068353</td>\n",
              "      <td>0.063146</td>\n",
              "      <td>0.069676</td>\n",
              "      <td>0.068225</td>\n",
              "      <td>0.015193</td>\n",
              "      <td>0.404455</td>\n",
              "      <td>0.582708</td>\n",
              "      <td>0.355448</td>\n",
              "      <td>0.257256</td>\n",
              "      <td>0.017838</td>\n",
              "      <td>0.278247</td>\n",
              "      <td>0.154541</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113243</th>\n",
              "      <td>2023-01-01 09:30:00</td>\n",
              "      <td>0.194755</td>\n",
              "      <td>0.189816</td>\n",
              "      <td>0.196793</td>\n",
              "      <td>0.195100</td>\n",
              "      <td>0.021886</td>\n",
              "      <td>0.531351</td>\n",
              "      <td>0.579733</td>\n",
              "      <td>0.265645</td>\n",
              "      <td>0.509961</td>\n",
              "      <td>0.004448</td>\n",
              "      <td>0.360762</td>\n",
              "      <td>0.322605</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113244</th>\n",
              "      <td>2023-01-01 09:45:00</td>\n",
              "      <td>0.195020</td>\n",
              "      <td>0.189961</td>\n",
              "      <td>0.196969</td>\n",
              "      <td>0.195193</td>\n",
              "      <td>0.030064</td>\n",
              "      <td>0.566102</td>\n",
              "      <td>0.580277</td>\n",
              "      <td>0.267470</td>\n",
              "      <td>0.592898</td>\n",
              "      <td>0.004507</td>\n",
              "      <td>0.330640</td>\n",
              "      <td>0.333334</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113245</th>\n",
              "      <td>2023-01-01 10:00:00</td>\n",
              "      <td>0.195120</td>\n",
              "      <td>0.189971</td>\n",
              "      <td>0.197090</td>\n",
              "      <td>0.195270</td>\n",
              "      <td>0.029205</td>\n",
              "      <td>0.593258</td>\n",
              "      <td>0.580852</td>\n",
              "      <td>0.269243</td>\n",
              "      <td>0.637620</td>\n",
              "      <td>0.004297</td>\n",
              "      <td>0.301822</td>\n",
              "      <td>0.399368</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113246</th>\n",
              "      <td>2023-01-01 10:15:00</td>\n",
              "      <td>0.195186</td>\n",
              "      <td>0.190037</td>\n",
              "      <td>0.197191</td>\n",
              "      <td>0.195288</td>\n",
              "      <td>0.019853</td>\n",
              "      <td>0.599933</td>\n",
              "      <td>0.581341</td>\n",
              "      <td>0.270448</td>\n",
              "      <td>0.668272</td>\n",
              "      <td>0.004016</td>\n",
              "      <td>0.279608</td>\n",
              "      <td>0.448883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113247</th>\n",
              "      <td>2023-01-01 10:30:00</td>\n",
              "      <td>0.195203</td>\n",
              "      <td>0.189996</td>\n",
              "      <td>0.197096</td>\n",
              "      <td>0.195219</td>\n",
              "      <td>0.024046</td>\n",
              "      <td>0.564464</td>\n",
              "      <td>0.581600</td>\n",
              "      <td>0.268988</td>\n",
              "      <td>0.617334</td>\n",
              "      <td>0.003887</td>\n",
              "      <td>0.257289</td>\n",
              "      <td>0.463897</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113215 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      time      open      high       low     close    volume  \\\n",
              "33     2019-10-01 08:15:00  0.069553  0.064224  0.070680  0.069009  0.009489   \n",
              "34     2019-10-01 08:30:00  0.068929  0.063845  0.070526  0.069169  0.011798   \n",
              "35     2019-10-01 08:45:00  0.069071  0.063939  0.070816  0.069314  0.005839   \n",
              "36     2019-10-01 09:00:00  0.069243  0.063893  0.069676  0.068435  0.017587   \n",
              "37     2019-10-01 09:15:00  0.068353  0.063146  0.069676  0.068225  0.015193   \n",
              "...                    ...       ...       ...       ...       ...       ...   \n",
              "113243 2023-01-01 09:30:00  0.194755  0.189816  0.196793  0.195100  0.021886   \n",
              "113244 2023-01-01 09:45:00  0.195020  0.189961  0.196969  0.195193  0.030064   \n",
              "113245 2023-01-01 10:00:00  0.195120  0.189971  0.197090  0.195270  0.029205   \n",
              "113246 2023-01-01 10:15:00  0.195186  0.190037  0.197191  0.195288  0.019853   \n",
              "113247 2023-01-01 10:30:00  0.195203  0.189996  0.197096  0.195219  0.024046   \n",
              "\n",
              "             RSI      MACD       OBV       CCI       ATR       ADX       MFI  \\\n",
              "33      0.494393  0.589019  0.356367  0.424339  0.017151  0.332065  0.239028   \n",
              "34      0.514935  0.587832  0.357083  0.407575  0.016798  0.304525  0.177759   \n",
              "35      0.533497  0.587086  0.357438  0.456659  0.016002  0.277955  0.233518   \n",
              "36      0.426038  0.584865  0.356370  0.295306  0.017881  0.278106  0.213643   \n",
              "37      0.404455  0.582708  0.355448  0.257256  0.017838  0.278247  0.154541   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "113243  0.531351  0.579733  0.265645  0.509961  0.004448  0.360762  0.322605   \n",
              "113244  0.566102  0.580277  0.267470  0.592898  0.004507  0.330640  0.333334   \n",
              "113245  0.593258  0.580852  0.269243  0.637620  0.004297  0.301822  0.399368   \n",
              "113246  0.599933  0.581341  0.270448  0.668272  0.004016  0.279608  0.448883   \n",
              "113247  0.564464  0.581600  0.268988  0.617334  0.003887  0.257289  0.463897   \n",
              "\n",
              "         UP  DOWN  \n",
              "33      1.0   0.0  \n",
              "34      1.0   0.0  \n",
              "35      0.0   1.0  \n",
              "36      0.0   1.0  \n",
              "37      1.0   0.0  \n",
              "...     ...   ...  \n",
              "113243  1.0   0.0  \n",
              "113244  1.0   0.0  \n",
              "113245  1.0   0.0  \n",
              "113246  0.0   1.0  \n",
              "113247  1.0   0.0  \n",
              "\n",
              "[113215 rows x 15 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fJySHQc1vvij"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0    56969\n",
              "0.0    56246\n",
              "Name: UP, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['UP'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "assMge-pvvik"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    57001\n",
              "1.0    56214\n",
              "Name: DOWN, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['DOWN'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G30PhZn8vvik"
      },
      "source": [
        "看起來數據蠻平衡的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhAI0s7vvik"
      },
      "source": [
        "# 儲存資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5G-LQyMFvvik"
      },
      "outputs": [],
      "source": [
        "df.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGf37pdovvik"
      },
      "source": [
        "# 分割成X、y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J8yawScBvvik"
      },
      "outputs": [],
      "source": [
        "\n",
        "X,y = list(),list()\n",
        "ref_bar = 10\n",
        "\n",
        "for i in range(len(df)-ref_bar):\n",
        "    #df.iloc.values 會回傳一個numpy array\n",
        "    X.append(df.iloc[i:i+ref_bar, 1:13].values) # i to i+ref_bar-1\n",
        "    y.append(df.iloc[i+ref_bar-1, 13:].values) # i+ref_bar-1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nVAjEG8Nvvik"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.06955319, 0.06422388, 0.07068038, 0.06900893, 0.00948854,\n",
              "        0.49439341, 0.58901944, 0.35636723, 0.42433911, 0.0171507 ,\n",
              "        0.33206521, 0.23902832],\n",
              "       [0.06892894, 0.06384478, 0.07052581, 0.06916903, 0.01179802,\n",
              "        0.51493541, 0.58783218, 0.35708331, 0.40757545, 0.01679846,\n",
              "        0.30452492, 0.17775859],\n",
              "       [0.06907147, 0.06393882, 0.07081624, 0.06931354, 0.00583873,\n",
              "        0.53349668, 0.58708598, 0.35743769, 0.45665891, 0.01600159,\n",
              "        0.27795504, 0.23351751],\n",
              "       [0.06924284, 0.06389296, 0.06967571, 0.06843534, 0.01758742,\n",
              "        0.42603842, 0.58486506, 0.35637022, 0.29530612, 0.01788137,\n",
              "        0.27810649, 0.21364349],\n",
              "       [0.06835313, 0.06314604, 0.06967571, 0.06822465, 0.01519295,\n",
              "        0.40445498, 0.58270768, 0.35544809, 0.25725617, 0.01783761,\n",
              "        0.27824712, 0.15454057],\n",
              "       [0.06813225, 0.06330802, 0.06976876, 0.06848084, 0.01153835,\n",
              "        0.44083766, 0.5814595 , 0.35614841, 0.34607659, 0.01796232,\n",
              "        0.27313944, 0.24075876],\n",
              "       [0.0683337 , 0.06313569, 0.06986521, 0.06840125, 0.00700491,\n",
              "        0.43180696, 0.58033746, 0.35572325, 0.37075367, 0.01743448,\n",
              "        0.26839659, 0.24457198],\n",
              "       [0.06832352, 0.06352745, 0.07009613, 0.0687782 , 0.00859865,\n",
              "        0.48511493, 0.5801434 , 0.35624514, 0.44498188, 0.01733275,\n",
              "        0.25138015, 0.31539743],\n",
              "       [0.06868353, 0.06360543, 0.07023245, 0.06858371, 0.00844426,\n",
              "        0.46077407, 0.57965678, 0.35573262, 0.45408742, 0.01709623,\n",
              "        0.23321071, 0.38111527],\n",
              "       [0.06848131, 0.06312766, 0.06987664, 0.06839817, 0.00803362,\n",
              "        0.43798444, 0.57896249, 0.35524502, 0.40898516, 0.01658771,\n",
              "        0.22554041, 0.37434816]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]#這裡會出現10個array，每個array裡面有12個數字，分別是open high low close volume RSI MACD OBV CCI ATR ADX MFI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZdEmCm_Qvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.0, 1.0], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MQMldPJgvvil"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "X = torch.tensor(X, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mm5Q6Cjavvil"
      },
      "outputs": [],
      "source": [
        "y = np.array(y,dtype=np.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5nUKlKubvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7kxTYq8tvvil"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([113205, 10, 12]) , y shape: torch.Size([113205, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X shape: {X.shape} , y shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1bAuFUJpvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0696, 0.0642, 0.0707, 0.0690, 0.0095, 0.4944, 0.5890, 0.3564, 0.4243,\n",
              "         0.0172, 0.3321, 0.2390],\n",
              "        [0.0689, 0.0638, 0.0705, 0.0692, 0.0118, 0.5149, 0.5878, 0.3571, 0.4076,\n",
              "         0.0168, 0.3045, 0.1778],\n",
              "        [0.0691, 0.0639, 0.0708, 0.0693, 0.0058, 0.5335, 0.5871, 0.3574, 0.4567,\n",
              "         0.0160, 0.2780, 0.2335],\n",
              "        [0.0692, 0.0639, 0.0697, 0.0684, 0.0176, 0.4260, 0.5849, 0.3564, 0.2953,\n",
              "         0.0179, 0.2781, 0.2136],\n",
              "        [0.0684, 0.0631, 0.0697, 0.0682, 0.0152, 0.4045, 0.5827, 0.3554, 0.2573,\n",
              "         0.0178, 0.2782, 0.1545],\n",
              "        [0.0681, 0.0633, 0.0698, 0.0685, 0.0115, 0.4408, 0.5815, 0.3561, 0.3461,\n",
              "         0.0180, 0.2731, 0.2408],\n",
              "        [0.0683, 0.0631, 0.0699, 0.0684, 0.0070, 0.4318, 0.5803, 0.3557, 0.3708,\n",
              "         0.0174, 0.2684, 0.2446],\n",
              "        [0.0683, 0.0635, 0.0701, 0.0688, 0.0086, 0.4851, 0.5801, 0.3562, 0.4450,\n",
              "         0.0173, 0.2514, 0.3154],\n",
              "        [0.0687, 0.0636, 0.0702, 0.0686, 0.0084, 0.4608, 0.5797, 0.3557, 0.4541,\n",
              "         0.0171, 0.2332, 0.3811],\n",
              "        [0.0685, 0.0631, 0.0699, 0.0684, 0.0080, 0.4380, 0.5790, 0.3552, 0.4090,\n",
              "         0.0166, 0.2255, 0.3743]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XgiJoWzjvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1.])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDKqaaoKvvil"
      },
      "source": [
        "# 建立資料集類別\n",
        "\n",
        "- 要繼承torch.utils.data.Dataset\n",
        "- 要實作`__len__`、`__getitem__`\n",
        "- 後面要用DataLoader取用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jLDT0sbfvvim"
      },
      "outputs": [],
      "source": [
        "#用sklearn來分成train val test\n",
        "# train:val:test = 6:3:1\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CSgwdCotvvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: torch.Size([67923, 10, 12]) , y_train shape: torch.Size([67923, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape: {X_train.shape} , y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ep8tt8-avvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_test shape: torch.Size([33962, 10, 12]) , y_test shape: torch.Size([33962, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_test shape: {X_test.shape} , y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RPqE-CPfvvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_val shape: torch.Size([11320, 10, 12]) , y_val shape: torch.Size([11320, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_val shape: {X_val.shape} , y_val shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y0NmS_Lqvvim"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-5DjuhEyvvim"
      },
      "outputs": [],
      "source": [
        "class ValDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qHMCNEm6vvim"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ChyqvyFKvvim"
      },
      "outputs": [],
      "source": [
        "train_dataset = TrainDataset(X_train, y_train)\n",
        "val_dataset = ValDataset(X_val, y_val)\n",
        "test_dataset = TestDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib09cuxtvvim"
      },
      "source": [
        "# 建立模型\n",
        "\n",
        "- 要繼承torch.nn.Module\n",
        "- 可能要多建立不同的模型，到時候看結果再調整 -> 先讓數據流得通，再去看成績做調整。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ga66dLL8vvim"
      },
      "source": [
        "- ver1 -> CNN+MLP\n",
        "- ver2 -> CNN+LSTM+MLP\n",
        "- ver3 -> CNN+GRU+MLP\n",
        "- ver4 -> CNN+LSTM+GRU+MLP\n",
        "- ver5 -> CNN+GRU+MLP+Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "L3Da8Y1avvin"
      },
      "outputs": [],
      "source": [
        "class SelectItem(torch.nn.Module):#這是用來取出多個輸出其中一個的輸出，如果不用sequential的話，就可以不用這個\n",
        "    def __init__(self, item_index):\n",
        "        super(SelectItem, self).__init__()\n",
        "        self._name = 'selectitem'\n",
        "        self.item_index = item_index\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return inputs[self.item_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cYU2NkZmvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver1(nn.Module): #CNN+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver1, self).__init__()\n",
        "        self.name = \"CCV-1\"\n",
        "        self.spare_layer = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 4, 3, stride=4, padding=1),\n",
        "            torch.nn.ReLU())\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 512),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 1024), \n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.ReLU())\n",
        "        self.fusion = nn.Sequential(\n",
        "            torch.nn.Linear(6, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.Softmax(dim=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.spare_layer(x)\n",
        "        x = x.T\n",
        "        x1 = self.net(x[0])\n",
        "        x2 = self.net(x[1])\n",
        "        x3 = self.net(x[2])\n",
        "        x = torch.cat((x1,x2,x3),0)\n",
        "        x = self.fusion(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qnyaDPbRvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver2(nn.Module): #CNN+LSTM+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver2, self).__init__()\n",
        "        self.name = \"CCV-2\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.LSTM(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64,2),\n",
        "            torch.nn.Softmax(dim=0))\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BwOtPcKSvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver3(nn.Module):#CNN+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver3, self).__init__()\n",
        "        self.name = \"CCV-3\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64,2),\n",
        "            torch.nn.ELU()\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        # print(f\"=>{F.softmax(x, dim=0)}\")\n",
        "        x = F.softmax(x, dim=0)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "AWW4C12svvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver4(nn.Module):#CNN+LSTM+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver4, self).__init__()\n",
        "        self.name = \"CCV-4\"\n",
        "        self.batch_size = 1\n",
        "        self.spare_layer = torch.nn.Conv1d(10, 2, 3, stride=3, padding=1)\n",
        "        self.gru = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64, 2))\n",
        "        self.lstm = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.LSTM(128, 256, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(256, 512, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(512, 256, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(256, 128, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64, 2))\n",
        "        self.fusion = nn.Sequential(\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.Softmax(dim=0)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.spare_layer(x)\n",
        "        x1 , x2 = x[0], x[1]\n",
        "        x1 = x1.view(1,1,4)\n",
        "        x2 = x2.view(1,1,4)\n",
        "        out1 = self.gru(x1)\n",
        "        out2 = self.lstm(x2)\n",
        "        x = torch.cat((out1,out2),2)\n",
        "        x = self.fusion(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNwithDropout(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNwithDropout, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1 , 128),\n",
        "            nn.Linear(128, out_channels)\n",
        "        )\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Conv1d(64, 1, kernel_size=3, padding=1),\n",
        "            SelectItem(0),\n",
        "            nn.Linear(2,16),\n",
        "            nn.Linear(16,64),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64,128),\n",
        "            nn.Linear(128,2),\n",
        "            nn.ELU(),\n",
        "            nn.Softmax(dim=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output_layer(self.net(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "class crypto_classfier_ver5(nn.Module):#CNN+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver5, self).__init__()\n",
        "        self.name = \"CCV-5\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.GRU(64, 32, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.GRU(32, 16, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(16,2),\n",
        "            torch.nn.Softmax(dim=0)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SS4jRXisvvin"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 12])\n",
            "torch.Size([2])\n",
            "tensor([[0.0982, 0.0933, 0.1000, 0.0987, 0.0118, 0.5241, 0.5753, 0.4052, 0.6211,\n",
            "         0.0128, 0.3322, 0.4336],\n",
            "        [0.0987, 0.0934, 0.1001, 0.0985, 0.0111, 0.4818, 0.5760, 0.4045, 0.6294,\n",
            "         0.0130, 0.3030, 0.4262],\n",
            "        [0.0984, 0.0931, 0.0999, 0.0983, 0.0097, 0.4599, 0.5764, 0.4039, 0.5574,\n",
            "         0.0126, 0.2822, 0.4428],\n",
            "        [0.0982, 0.0932, 0.1000, 0.0984, 0.0062, 0.4655, 0.5768, 0.4043, 0.5823,\n",
            "         0.0123, 0.2579, 0.5099],\n",
            "        [0.0983, 0.0933, 0.1001, 0.0984, 0.0101, 0.4657, 0.5772, 0.4049, 0.6017,\n",
            "         0.0122, 0.2399, 0.5134],\n",
            "        [0.0983, 0.0934, 0.1001, 0.0987, 0.0078, 0.5234, 0.5781, 0.4054, 0.6201,\n",
            "         0.0121, 0.2246, 0.5944],\n",
            "        [0.0986, 0.0933, 0.1002, 0.0986, 0.0089, 0.5176, 0.5787, 0.4048, 0.6047,\n",
            "         0.0116, 0.2104, 0.7049],\n",
            "        [0.0986, 0.0932, 0.0998, 0.0981, 0.0109, 0.4183, 0.5783, 0.4042, 0.4872,\n",
            "         0.0120, 0.2023, 0.6055],\n",
            "        [0.0980, 0.0931, 0.0998, 0.0984, 0.0122, 0.4773, 0.5785, 0.4049, 0.5062,\n",
            "         0.0121, 0.1952, 0.6050],\n",
            "        [0.0983, 0.0936, 0.1000, 0.0988, 0.0280, 0.5511, 0.5795, 0.4066, 0.6191,\n",
            "         0.0129, 0.1835, 0.7163]])\n",
            "tensor([0., 1.])\n"
          ]
        }
      ],
      "source": [
        "lab_tensor = train_dataset[0][0]\n",
        "lab_ans_tensor = train_dataset[0][1]\n",
        "print(lab_tensor.shape)\n",
        "print(lab_ans_tensor.shape)\n",
        "print(lab_tensor)\n",
        "print(lab_ans_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5813, 0.4187], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "lab_models = crypto_classfier_ver4()\n",
        "lab_out = lab_models(lab_tensor)\n",
        "print(lab_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "lab_target = torch.tensor([0.,1.])\n",
        "lab_test_ansers = [torch.tensor([1-(i*0.1),i*0.1]) for i in range(1,10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BCE loss:2.3026 ans:tensor([0.9000, 0.1000])\n",
            "CE loss:1.1711 ans:tensor([0.9000, 0.1000])\n",
            "MSE loss:0.8100 ans:tensor([0.9000, 0.1000])\n",
            "=====================================\n",
            "BCE loss:1.6094 ans:tensor([0.8000, 0.2000])\n",
            "CE loss:1.0375 ans:tensor([0.8000, 0.2000])\n",
            "MSE loss:0.6400 ans:tensor([0.8000, 0.2000])\n",
            "=====================================\n",
            "BCE loss:1.2040 ans:tensor([0.7000, 0.3000])\n",
            "CE loss:0.9130 ans:tensor([0.7000, 0.3000])\n",
            "MSE loss:0.4900 ans:tensor([0.7000, 0.3000])\n",
            "=====================================\n",
            "BCE loss:0.9163 ans:tensor([0.6000, 0.4000])\n",
            "CE loss:0.7981 ans:tensor([0.6000, 0.4000])\n",
            "MSE loss:0.3600 ans:tensor([0.6000, 0.4000])\n",
            "=====================================\n",
            "BCE loss:0.6931 ans:tensor([0.5000, 0.5000])\n",
            "CE loss:0.6931 ans:tensor([0.5000, 0.5000])\n",
            "MSE loss:0.2500 ans:tensor([0.5000, 0.5000])\n",
            "=====================================\n",
            "BCE loss:0.5108 ans:tensor([0.4000, 0.6000])\n",
            "CE loss:0.5981 ans:tensor([0.4000, 0.6000])\n",
            "MSE loss:0.1600 ans:tensor([0.4000, 0.6000])\n",
            "=====================================\n",
            "BCE loss:0.3567 ans:tensor([0.3000, 0.7000])\n",
            "CE loss:0.5130 ans:tensor([0.3000, 0.7000])\n",
            "MSE loss:0.0900 ans:tensor([0.3000, 0.7000])\n",
            "=====================================\n",
            "BCE loss:0.2231 ans:tensor([0.2000, 0.8000])\n",
            "CE loss:0.4375 ans:tensor([0.2000, 0.8000])\n",
            "MSE loss:0.0400 ans:tensor([0.2000, 0.8000])\n",
            "=====================================\n",
            "BCE loss:0.1054 ans:tensor([0.1000, 0.9000])\n",
            "CE loss:0.3711 ans:tensor([0.1000, 0.9000])\n",
            "MSE loss:0.0100 ans:tensor([0.1000, 0.9000])\n",
            "=====================================\n"
          ]
        }
      ],
      "source": [
        "for i in lab_test_ansers:\n",
        "    print(f\"BCE loss:{F.binary_cross_entropy(i, lab_target):.4f} ans:{i}\")\n",
        "    print(f\"CE loss:{F.cross_entropy(i.view(1,2), torch.tensor([1])):.4f} ans:{i}\")\n",
        "    print(f\"MSE loss:{F.mse_loss(i, lab_target):.4f} ans:{i}\")\n",
        "    print(\"=====================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nuI6u2Psvvin"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5549, 0.4451], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.5041, 0.4959], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4960, 0.5040], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.3447, 0.6553], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4212, 0.5788], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4900, 0.5100], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "lab_models = [crypto_classfier_ver1(), crypto_classfier_ver2(), crypto_classfier_ver3(), crypto_classfier_ver4(), crypto_classfier_ver5(), CNNwithDropout(10,2)]\n",
        "out_data = list(map(lambda x: x(lab_tensor), lab_models))\n",
        "\n",
        "for t in out_data:\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeIGq4dRvvio"
      },
      "source": [
        "## Note\n",
        "\n",
        "1) model\n",
        "    - `__init__`: define [layers](https://pytorch.org/docs/stable/nn.html)\n",
        "    - forward: forward pass -> compute prediction\n",
        "2) loss and optimizer\n",
        "    - lr: learning rate [default=0.001]\n",
        "    - momentum: momentum for optimizer [default=0.9]\n",
        "    - criterion: loss function [in torch.nn] eg.nn.BCELoss()\n",
        "    - optimizer: optimizer [in torch.optim] eg.torch.optim.SGD()\n",
        "        - eg. optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "3) training loop\n",
        "    - forward pass: compute prediction and loss\n",
        "\n",
        "        ```python\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        ```\n",
        "        \n",
        "    - backward pass: loss.backward()\n",
        "    - update weights: optimizer.step()\n",
        "    - zero the gradients: optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSv_yChTvvio"
      },
      "source": [
        "# TODO\n",
        "\n",
        "- 寫訓練方法\n",
        "    - using dataloader\n",
        "        - batch and epoch\n",
        "- 寫驗證方法\n",
        "    - using model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "BK2mvw2zvvio"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 12])\n",
            "torch.Size([1, 2])\n",
            "tensor(1.)\n",
            "torch.Size([2])\n",
            "tensor([1., 0.])\n",
            "tensor([0., 1.])\n"
          ]
        }
      ],
      "source": [
        "test_dataloader_temp = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "loss_f = nn.MSELoss()\n",
        "test_model = crypto_classfier_ver1()\n",
        "for ind,(x,y) in enumerate(test_dataloader_temp):\n",
        "    if ind == 50:\n",
        "        print(x.shape)\n",
        "        print(y.shape)\n",
        "        x = x[0]\n",
        "        y = y[0]\n",
        "        out= test_model(x)\n",
        "        out = torch.tensor([1.,0.]) if out[0] > out[1] else torch.tensor([0.,1.])\n",
        "        loss_val = loss_f(out, y)\n",
        "        print(loss_val)\n",
        "        print(out.shape)\n",
        "        print(out)\n",
        "        print(y)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rKt9wlA3vvio"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model:  CCV-5\n",
            "loss_function:  MSELoss()\n",
            "optimizer:  <class 'torch.optim.sgd.SGD'>\n",
            "lr:  0.0001\n",
            "epochs:  30\n",
            "batch_size:  1\n",
            "device:  cpu\n",
            "Train epoch:  0 i:  0 loss:  0.1862603724002838 out:  tensor([0.4316, 0.5684], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [44], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m out \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     36\u001b[0m loss \u001b[39m=\u001b[39m loss_function(out, y)\n\u001b[1;32m---> 37\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     38\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     39\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#setting loss function and optimizer\n",
        "loss_functions = [nn.MSELoss()]#, nn.BCELoss(),nn.CrossEntropyLoss()\n",
        "optimizers = [ torch.optim.SGD]#torch.optim.Adam,\n",
        "models = [crypto_classfier_ver5()]#crypto_classfier_ver1(), crypto_classfier_ver2(), crypto_classfier_ver3(), crypto_classfier_ver4(), CNNwithDropout(10,2)\n",
        "history = dict()\n",
        "lr = 0.0001\n",
        "epochs = 30\n",
        "batch_size = 1 #batch size 是一次讀取多少筆資料 我這邊只能設1 因為我們的資料是一筆一筆的\n",
        "#training\n",
        "for model in models:\n",
        "    for loss_function in loss_functions:\n",
        "        for optimizer in optimizers:\n",
        "            print(\"model: \", model.name)\n",
        "            print(\"loss_function: \", loss_function)\n",
        "            print(\"optimizer: \", optimizer)\n",
        "            print(\"lr: \", lr)\n",
        "            print(\"epochs: \", epochs)\n",
        "            print(\"batch_size: \", batch_size)\n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "            print(\"device: \", device)\n",
        "            optimizer = optimizer(model.parameters(), lr=lr)\n",
        "            train_loss = []\n",
        "            test_loss = []\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            for epoch in range(epochs):\n",
        "                for i, (x, y) in enumerate(train_loader):\n",
        "                    model.train()\n",
        "                    x = x[0]\n",
        "                    y = y[0]\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    out = model(x)\n",
        "                    loss = loss_function(out, y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss.append(loss.item())\n",
        "                    if i % 1000 == 0:\n",
        "                        print(\"Train epoch: \", epoch, \"i: \", i, \"loss: \", loss.item(), \"out: \", out, \"y: \", y)\n",
        "                for i, (x, y) in enumerate(test_loader):\n",
        "                    model.eval()\n",
        "                    x = x[0]\n",
        "                    y = y[0]\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    out = model(x)\n",
        "                    loss = loss_function(out, y)\n",
        "                    test_loss.append([loss.item(), model.parameters()])\n",
        "                    if i % 1000 == 0:\n",
        "                        print(\"epoch: \", epoch, \"i: \", i, \"loss: \", loss.item())\n",
        "                if epoch % 10 == 0:\n",
        "                    print(\"epoch: \", epoch, \"train_loss: \", train_loss[-1], \"test_loss: \", test_loss[-1])\n",
        "            history[model.name + str(loss_function) + str(optimizer)] = [train_loss[-1], test_loss[-1], model.parameters()]\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
