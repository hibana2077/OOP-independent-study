{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6epq6_O1vvia"
      },
      "source": [
        "[![GitHub](https://img.shields.io/badge/Github-hibana2077-blue?style=plastic-square&logo=github)](https://github.com/hibana2077)\n",
        "[![Colab](https://img.shields.io/badge/Colab-Open%20in%20Colab-blue?style=plastic-square&logo=googlecolab)](https://colab.research.google.com/github/hibana2077/hibana2077/blob/master/train/train.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t38eQJt0vvid"
      },
      "source": [
        "如果要訓練這份資料集會需要安裝talib套件，請參考[這裡](https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib)下載對應的版本，並使用pip安裝。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWr_Ksvyv3Ro",
        "outputId": "a1ee08c2-55e0-4e05-a5e3-39430fde8c45"
      },
      "outputs": [],
      "source": [
        "# !pip install ccxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSuyiZlLwOO5",
        "outputId": "3d1ec1a2-6001-4306-8424-1923934b2884"
      },
      "outputs": [],
      "source": [
        "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "# !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "# %cd ta-lib\n",
        "# !./configure --prefix=/usr\n",
        "# !make\n",
        "# !make install\n",
        "# !pip install Ta-Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "0dEqkDzevvie",
        "outputId": "4ef1a61d-0ce2-40b5-8102-d6a51827ef87"
      },
      "outputs": [],
      "source": [
        "from ccxt import binance\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from talib import abstract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H59nhzEFvvif"
      },
      "source": [
        "# 環境整理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zjpnlfgcvvif"
      },
      "outputs": [],
      "source": [
        "ls_dir = os.listdir(path=\"..\")\n",
        "if \"data\" not in ls_dir:\n",
        "    os.mkdir(path=\"../data\")\n",
        "if \"model\" not in ls_dir:\n",
        "    os.mkdir(path=\"../model\")\n",
        "if \"data\" in ls_dir:\n",
        "    ls_dir = os.listdir(path=\"../data\")\n",
        "    #remove all files in data folder\n",
        "    for file in ls_dir:os.remove(path=\"../data/\"+file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG1FGxMUvvig"
      },
      "source": [
        "# 下載資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "29klRj8yvvig"
      },
      "outputs": [],
      "source": [
        "# Binance BTC/USDT 1h candles from 2020-01-01 to 2021-01-01\n",
        "\n",
        "binance = binance()\n",
        "symbol = 'BTC/USDT'\n",
        "timeframe = '1h'\n",
        "file_name = f\"../data/{symbol.replace('/', '_')}_{timeframe}.csv\"\n",
        "start = binance.parse8601('2019-10-01T00:00:00Z')\n",
        "end = binance.parse8601('2022-12-30T00:00:00Z')\n",
        "cnt_time = start\n",
        "data = []\n",
        "while cnt_time < end:\n",
        "    ohlcv = binance.fetch_ohlcv(symbol, timeframe, cnt_time)\n",
        "    data += ohlcv\n",
        "    cnt_time = ohlcv[-1][0] + 3600000 # 1h in ms    \n",
        "df = pd.DataFrame(data, columns=['time', 'open', 'high', 'low', 'close', 'volume'])\n",
        "df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
        "df.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhcDY9sbvvih"
      },
      "source": [
        "# 讀取資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT6TVXPQvvih"
      },
      "outputs": [],
      "source": [
        "#如果有下载好的數據，可以直接讀取\n",
        "data_file = '../data/btc_usdt_1h.csv' #-> 可以自行更換\n",
        "df = pd.read_csv(data_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz939phEvvih"
      },
      "source": [
        "# 數據處理\n",
        "\n",
        "- 計算RSI\n",
        "- 計算MACD\n",
        "- 計算OBV\n",
        "- 計算CCI\n",
        "- 改成變化百分比 -> 標準化\n",
        "\n",
        "關於技術指標的說明可以參考[這裡](https://www.investopedia.com/terms/t/technicalindicator.asp)，或是google。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cWEqDOiVvvih"
      },
      "outputs": [],
      "source": [
        "df['RSI'] = abstract.RSI(df, timeperiod=14)\n",
        "df['MACD'] = abstract.MACD(df, fastperiod=12, slowperiod=26, signalperiod=9)['macd'] #只取MACD\n",
        "df['OBV'] = abstract.OBV(df, timeperiod=14)\n",
        "df['CCI'] = abstract.CCI(df, timeperiod=14)\n",
        "df['ATR'] = abstract.ATR(df, timeperiod=14)\n",
        "df['ADX'] = abstract.ADX(df, timeperiod=14)\n",
        "df['MFI'] = abstract.MFI(df, timeperiod=14)\n",
        "df['CLOSE_percent'] = df['close'].pct_change()\n",
        "#由於RSI MACD OBV CCI 他們已經是標準化的，所以不需要再標準化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDPm_zt2vvii"
      },
      "source": [
        "# 設定買賣點\n",
        "\n",
        "將買賣點分為下跌、上漲、不動，並將數據轉成one-hot編碼。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kQ0vSu6Yvvii"
      },
      "outputs": [],
      "source": [
        "df['UP'] = df['CLOSE_percent'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df['DOWN'] = df['CLOSE_percent'].apply(lambda x: 1 if x < 0 else 0)\n",
        "df['UP'] = df['UP'].shift(-1) #shift UP DOWN 一個單位，因為我們要預測的是下一個時間點的漲跌\n",
        "df['DOWN'] = df['DOWN'].shift(-1)\n",
        "\n",
        "df = df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k77OIN-dvvii"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>OBV</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>ADX</th>\n",
              "      <th>MFI</th>\n",
              "      <th>CLOSE_percent</th>\n",
              "      <th>UP</th>\n",
              "      <th>DOWN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-10-02 09:00:00</td>\n",
              "      <td>8237.59</td>\n",
              "      <td>8267.26</td>\n",
              "      <td>8220.46</td>\n",
              "      <td>8234.67</td>\n",
              "      <td>730.375055</td>\n",
              "      <td>48.723435</td>\n",
              "      <td>-36.978752</td>\n",
              "      <td>-5388.066483</td>\n",
              "      <td>-32.078733</td>\n",
              "      <td>79.716399</td>\n",
              "      <td>16.445918</td>\n",
              "      <td>43.517312</td>\n",
              "      <td>-0.000397</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-10-02 10:00:00</td>\n",
              "      <td>8235.00</td>\n",
              "      <td>8258.78</td>\n",
              "      <td>8211.05</td>\n",
              "      <td>8255.93</td>\n",
              "      <td>721.600120</td>\n",
              "      <td>51.222502</td>\n",
              "      <td>-33.420223</td>\n",
              "      <td>-4666.466363</td>\n",
              "      <td>-22.331369</td>\n",
              "      <td>77.431656</td>\n",
              "      <td>15.656964</td>\n",
              "      <td>40.954942</td>\n",
              "      <td>0.002582</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-10-02 11:00:00</td>\n",
              "      <td>8255.47</td>\n",
              "      <td>8289.00</td>\n",
              "      <td>8225.53</td>\n",
              "      <td>8269.04</td>\n",
              "      <td>912.918303</td>\n",
              "      <td>52.751719</td>\n",
              "      <td>-29.205532</td>\n",
              "      <td>-3753.548060</td>\n",
              "      <td>21.716060</td>\n",
              "      <td>76.434395</td>\n",
              "      <td>15.521321</td>\n",
              "      <td>47.604680</td>\n",
              "      <td>0.001588</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-10-02 12:00:00</td>\n",
              "      <td>8268.67</td>\n",
              "      <td>8300.00</td>\n",
              "      <td>8208.00</td>\n",
              "      <td>8229.10</td>\n",
              "      <td>1510.638503</td>\n",
              "      <td>47.831816</td>\n",
              "      <td>-28.756695</td>\n",
              "      <td>-5264.186563</td>\n",
              "      <td>0.716845</td>\n",
              "      <td>77.546224</td>\n",
              "      <td>14.970377</td>\n",
              "      <td>45.298104</td>\n",
              "      <td>-0.004830</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-10-02 13:00:00</td>\n",
              "      <td>8230.40</td>\n",
              "      <td>8261.04</td>\n",
              "      <td>8200.00</td>\n",
              "      <td>8216.80</td>\n",
              "      <td>1317.184129</td>\n",
              "      <td>46.396694</td>\n",
              "      <td>-29.058526</td>\n",
              "      <td>-6581.370692</td>\n",
              "      <td>-38.372502</td>\n",
              "      <td>76.367208</td>\n",
              "      <td>14.265805</td>\n",
              "      <td>44.030923</td>\n",
              "      <td>-0.001495</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28453</th>\n",
              "      <td>2022-12-31 00:00:00</td>\n",
              "      <td>16607.48</td>\n",
              "      <td>16616.37</td>\n",
              "      <td>16578.00</td>\n",
              "      <td>16580.32</td>\n",
              "      <td>4264.258480</td>\n",
              "      <td>53.104081</td>\n",
              "      <td>2.759274</td>\n",
              "      <td>-393124.472793</td>\n",
              "      <td>89.212926</td>\n",
              "      <td>58.593323</td>\n",
              "      <td>26.989753</td>\n",
              "      <td>48.874053</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28454</th>\n",
              "      <td>2022-12-31 01:00:00</td>\n",
              "      <td>16580.32</td>\n",
              "      <td>16583.69</td>\n",
              "      <td>16562.36</td>\n",
              "      <td>16568.24</td>\n",
              "      <td>4007.775890</td>\n",
              "      <td>51.354857</td>\n",
              "      <td>3.169750</td>\n",
              "      <td>-397132.248683</td>\n",
              "      <td>50.044160</td>\n",
              "      <td>55.931657</td>\n",
              "      <td>25.522369</td>\n",
              "      <td>49.121993</td>\n",
              "      <td>-0.000729</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28455</th>\n",
              "      <td>2022-12-31 02:00:00</td>\n",
              "      <td>16568.23</td>\n",
              "      <td>16579.79</td>\n",
              "      <td>16560.47</td>\n",
              "      <td>16575.94</td>\n",
              "      <td>3569.361150</td>\n",
              "      <td>52.430467</td>\n",
              "      <td>4.069471</td>\n",
              "      <td>-393562.887533</td>\n",
              "      <td>44.708698</td>\n",
              "      <td>53.316539</td>\n",
              "      <td>24.112844</td>\n",
              "      <td>54.624178</td>\n",
              "      <td>0.000465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28456</th>\n",
              "      <td>2022-12-31 03:00:00</td>\n",
              "      <td>16576.18</td>\n",
              "      <td>16577.38</td>\n",
              "      <td>16550.01</td>\n",
              "      <td>16552.46</td>\n",
              "      <td>3814.652160</td>\n",
              "      <td>48.881119</td>\n",
              "      <td>2.854956</td>\n",
              "      <td>-397377.539693</td>\n",
              "      <td>14.442228</td>\n",
              "      <td>51.463215</td>\n",
              "      <td>22.535743</td>\n",
              "      <td>55.957329</td>\n",
              "      <td>-0.001417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28457</th>\n",
              "      <td>2022-12-31 04:00:00</td>\n",
              "      <td>16552.46</td>\n",
              "      <td>16555.59</td>\n",
              "      <td>16541.75</td>\n",
              "      <td>16551.89</td>\n",
              "      <td>3226.938410</td>\n",
              "      <td>48.794761</td>\n",
              "      <td>1.825408</td>\n",
              "      <td>-400604.478103</td>\n",
              "      <td>-39.808844</td>\n",
              "      <td>48.775842</td>\n",
              "      <td>20.994385</td>\n",
              "      <td>63.655091</td>\n",
              "      <td>-0.000034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28425 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time      open      high       low     close  \\\n",
              "33    2019-10-02 09:00:00   8237.59   8267.26   8220.46   8234.67   \n",
              "34    2019-10-02 10:00:00   8235.00   8258.78   8211.05   8255.93   \n",
              "35    2019-10-02 11:00:00   8255.47   8289.00   8225.53   8269.04   \n",
              "36    2019-10-02 12:00:00   8268.67   8300.00   8208.00   8229.10   \n",
              "37    2019-10-02 13:00:00   8230.40   8261.04   8200.00   8216.80   \n",
              "...                   ...       ...       ...       ...       ...   \n",
              "28453 2022-12-31 00:00:00  16607.48  16616.37  16578.00  16580.32   \n",
              "28454 2022-12-31 01:00:00  16580.32  16583.69  16562.36  16568.24   \n",
              "28455 2022-12-31 02:00:00  16568.23  16579.79  16560.47  16575.94   \n",
              "28456 2022-12-31 03:00:00  16576.18  16577.38  16550.01  16552.46   \n",
              "28457 2022-12-31 04:00:00  16552.46  16555.59  16541.75  16551.89   \n",
              "\n",
              "            volume        RSI       MACD            OBV        CCI        ATR  \\\n",
              "33      730.375055  48.723435 -36.978752   -5388.066483 -32.078733  79.716399   \n",
              "34      721.600120  51.222502 -33.420223   -4666.466363 -22.331369  77.431656   \n",
              "35      912.918303  52.751719 -29.205532   -3753.548060  21.716060  76.434395   \n",
              "36     1510.638503  47.831816 -28.756695   -5264.186563   0.716845  77.546224   \n",
              "37     1317.184129  46.396694 -29.058526   -6581.370692 -38.372502  76.367208   \n",
              "...            ...        ...        ...            ...        ...        ...   \n",
              "28453  4264.258480  53.104081   2.759274 -393124.472793  89.212926  58.593323   \n",
              "28454  4007.775890  51.354857   3.169750 -397132.248683  50.044160  55.931657   \n",
              "28455  3569.361150  52.430467   4.069471 -393562.887533  44.708698  53.316539   \n",
              "28456  3814.652160  48.881119   2.854956 -397377.539693  14.442228  51.463215   \n",
              "28457  3226.938410  48.794761   1.825408 -400604.478103 -39.808844  48.775842   \n",
              "\n",
              "             ADX        MFI  CLOSE_percent   UP  DOWN  \n",
              "33     16.445918  43.517312      -0.000397  1.0   0.0  \n",
              "34     15.656964  40.954942       0.002582  1.0   0.0  \n",
              "35     15.521321  47.604680       0.001588  0.0   1.0  \n",
              "36     14.970377  45.298104      -0.004830  0.0   1.0  \n",
              "37     14.265805  44.030923      -0.001495  1.0   0.0  \n",
              "...          ...        ...            ...  ...   ...  \n",
              "28453  26.989753  48.874053      -0.001635  0.0   1.0  \n",
              "28454  25.522369  49.121993      -0.000729  1.0   0.0  \n",
              "28455  24.112844  54.624178       0.000465  0.0   1.0  \n",
              "28456  22.535743  55.957329      -0.001417  0.0   1.0  \n",
              "28457  20.994385  63.655091      -0.000034  0.0   1.0  \n",
              "\n",
              "[28425 rows x 16 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aTh7CyL-vvij"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['RSI'] = (df['RSI'] - df['RSI'].min()) / (df['RSI'].max() - df['RSI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['MACD'] = (df['MACD'] - df['MACD'].min()) / (df['MACD'].max() - df['MACD'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['OBV'] = (df['OBV'] - df['OBV'].min()) / (df['OBV'].max() - df['OBV'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CCI'] = (df['CCI'] - df['CCI'].min()) / (df['CCI'].max() - df['CCI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ATR'] = (df['ATR'] - df['ATR'].min()) / (df['ATR'].max() - df['ATR'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['ADX'] = (df['ADX'] - df['ADX'].min()) / (df['ADX'].max() - df['ADX'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['MFI'] = (df['MFI'] - df['MFI'].min()) / (df['MFI'].max() - df['MFI'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['open'] = (df['open'] - df['open'].min()) / (df['open'].max() - df['open'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['high'] = (df['high'] - df['high'].min()) / (df['high'].max() - df['high'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['low'] = (df['low'] - df['low'].min()) / (df['low'].max() - df['low'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['close'] = (df['close'] - df['close'].min()) / (df['close'].max() - df['close'].min())\n",
            "C:\\Users\\李軒豪\\AppData\\Local\\Temp\\ipykernel_15624\\1144569331.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['volume'] = (df['volume'] - df['volume'].min()) / (df['volume'].max() - df['volume'].min())\n"
          ]
        }
      ],
      "source": [
        "#正規化\n",
        "df['RSI'] = (df['RSI'] - df['RSI'].min()) / (df['RSI'].max() - df['RSI'].min())\n",
        "df['MACD'] = (df['MACD'] - df['MACD'].min()) / (df['MACD'].max() - df['MACD'].min())\n",
        "df['OBV'] = (df['OBV'] - df['OBV'].min()) / (df['OBV'].max() - df['OBV'].min())\n",
        "df['CCI'] = (df['CCI'] - df['CCI'].min()) / (df['CCI'].max() - df['CCI'].min())\n",
        "df['ATR'] = (df['ATR'] - df['ATR'].min()) / (df['ATR'].max() - df['ATR'].min())\n",
        "df['ADX'] = (df['ADX'] - df['ADX'].min()) / (df['ADX'].max() - df['ADX'].min())\n",
        "df['MFI'] = (df['MFI'] - df['MFI'].min()) / (df['MFI'].max() - df['MFI'].min())\n",
        "df['open'] = (df['open'] - df['open'].min()) / (df['open'].max() - df['open'].min())\n",
        "df['high'] = (df['high'] - df['high'].min()) / (df['high'].max() - df['high'].min())\n",
        "df['low'] = (df['low'] - df['low'].min()) / (df['low'].max() - df['low'].min())\n",
        "df['close'] = (df['close'] - df['close'].min()) / (df['close'].max() - df['close'].min())\n",
        "df['volume'] = (df['volume'] - df['volume'].min()) / (df['volume'].max() - df['volume'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\李軒豪\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "df.drop(['CLOSE_percent'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UYO1j5O-vvij"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>OBV</th>\n",
              "      <th>CCI</th>\n",
              "      <th>ATR</th>\n",
              "      <th>ADX</th>\n",
              "      <th>MFI</th>\n",
              "      <th>UP</th>\n",
              "      <th>DOWN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-10-02 09:00:00</td>\n",
              "      <td>0.063661</td>\n",
              "      <td>0.056799</td>\n",
              "      <td>0.068631</td>\n",
              "      <td>0.063625</td>\n",
              "      <td>0.005323</td>\n",
              "      <td>0.462730</td>\n",
              "      <td>0.547051</td>\n",
              "      <td>0.349256</td>\n",
              "      <td>0.465913</td>\n",
              "      <td>0.026936</td>\n",
              "      <td>0.131840</td>\n",
              "      <td>0.435173</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-10-02 10:00:00</td>\n",
              "      <td>0.063621</td>\n",
              "      <td>0.056667</td>\n",
              "      <td>0.068486</td>\n",
              "      <td>0.063955</td>\n",
              "      <td>0.005259</td>\n",
              "      <td>0.491218</td>\n",
              "      <td>0.547889</td>\n",
              "      <td>0.349723</td>\n",
              "      <td>0.476396</td>\n",
              "      <td>0.025946</td>\n",
              "      <td>0.121307</td>\n",
              "      <td>0.409549</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-10-02 11:00:00</td>\n",
              "      <td>0.063938</td>\n",
              "      <td>0.057136</td>\n",
              "      <td>0.068710</td>\n",
              "      <td>0.064158</td>\n",
              "      <td>0.006654</td>\n",
              "      <td>0.508651</td>\n",
              "      <td>0.548881</td>\n",
              "      <td>0.350314</td>\n",
              "      <td>0.523771</td>\n",
              "      <td>0.025513</td>\n",
              "      <td>0.119497</td>\n",
              "      <td>0.476047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-10-02 12:00:00</td>\n",
              "      <td>0.064142</td>\n",
              "      <td>0.057307</td>\n",
              "      <td>0.068439</td>\n",
              "      <td>0.063539</td>\n",
              "      <td>0.011010</td>\n",
              "      <td>0.452566</td>\n",
              "      <td>0.548987</td>\n",
              "      <td>0.349336</td>\n",
              "      <td>0.501186</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.112142</td>\n",
              "      <td>0.452981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-10-02 13:00:00</td>\n",
              "      <td>0.063549</td>\n",
              "      <td>0.056702</td>\n",
              "      <td>0.068315</td>\n",
              "      <td>0.063348</td>\n",
              "      <td>0.009600</td>\n",
              "      <td>0.436206</td>\n",
              "      <td>0.548916</td>\n",
              "      <td>0.348484</td>\n",
              "      <td>0.459144</td>\n",
              "      <td>0.025484</td>\n",
              "      <td>0.102736</td>\n",
              "      <td>0.440309</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28453</th>\n",
              "      <td>2022-12-31 00:00:00</td>\n",
              "      <td>0.193419</td>\n",
              "      <td>0.186463</td>\n",
              "      <td>0.197867</td>\n",
              "      <td>0.193009</td>\n",
              "      <td>0.031079</td>\n",
              "      <td>0.512667</td>\n",
              "      <td>0.556406</td>\n",
              "      <td>0.098259</td>\n",
              "      <td>0.596367</td>\n",
              "      <td>0.017779</td>\n",
              "      <td>0.272597</td>\n",
              "      <td>0.488741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28454</th>\n",
              "      <td>2022-12-31 01:00:00</td>\n",
              "      <td>0.192998</td>\n",
              "      <td>0.185956</td>\n",
              "      <td>0.197625</td>\n",
              "      <td>0.192822</td>\n",
              "      <td>0.029210</td>\n",
              "      <td>0.492727</td>\n",
              "      <td>0.556502</td>\n",
              "      <td>0.095665</td>\n",
              "      <td>0.554239</td>\n",
              "      <td>0.016625</td>\n",
              "      <td>0.253007</td>\n",
              "      <td>0.491220</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28455</th>\n",
              "      <td>2022-12-31 02:00:00</td>\n",
              "      <td>0.192810</td>\n",
              "      <td>0.185895</td>\n",
              "      <td>0.197596</td>\n",
              "      <td>0.192941</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.504989</td>\n",
              "      <td>0.556714</td>\n",
              "      <td>0.097975</td>\n",
              "      <td>0.548501</td>\n",
              "      <td>0.015492</td>\n",
              "      <td>0.234191</td>\n",
              "      <td>0.546242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28456</th>\n",
              "      <td>2022-12-31 03:00:00</td>\n",
              "      <td>0.192933</td>\n",
              "      <td>0.185858</td>\n",
              "      <td>0.197434</td>\n",
              "      <td>0.192577</td>\n",
              "      <td>0.027802</td>\n",
              "      <td>0.464528</td>\n",
              "      <td>0.556428</td>\n",
              "      <td>0.095506</td>\n",
              "      <td>0.515948</td>\n",
              "      <td>0.014688</td>\n",
              "      <td>0.213137</td>\n",
              "      <td>0.559573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28457</th>\n",
              "      <td>2022-12-31 04:00:00</td>\n",
              "      <td>0.192566</td>\n",
              "      <td>0.185519</td>\n",
              "      <td>0.197306</td>\n",
              "      <td>0.192568</td>\n",
              "      <td>0.023519</td>\n",
              "      <td>0.463543</td>\n",
              "      <td>0.556186</td>\n",
              "      <td>0.093417</td>\n",
              "      <td>0.457599</td>\n",
              "      <td>0.013523</td>\n",
              "      <td>0.192560</td>\n",
              "      <td>0.636551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28425 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     time      open      high       low     close    volume  \\\n",
              "33    2019-10-02 09:00:00  0.063661  0.056799  0.068631  0.063625  0.005323   \n",
              "34    2019-10-02 10:00:00  0.063621  0.056667  0.068486  0.063955  0.005259   \n",
              "35    2019-10-02 11:00:00  0.063938  0.057136  0.068710  0.064158  0.006654   \n",
              "36    2019-10-02 12:00:00  0.064142  0.057307  0.068439  0.063539  0.011010   \n",
              "37    2019-10-02 13:00:00  0.063549  0.056702  0.068315  0.063348  0.009600   \n",
              "...                   ...       ...       ...       ...       ...       ...   \n",
              "28453 2022-12-31 00:00:00  0.193419  0.186463  0.197867  0.193009  0.031079   \n",
              "28454 2022-12-31 01:00:00  0.192998  0.185956  0.197625  0.192822  0.029210   \n",
              "28455 2022-12-31 02:00:00  0.192810  0.185895  0.197596  0.192941  0.026014   \n",
              "28456 2022-12-31 03:00:00  0.192933  0.185858  0.197434  0.192577  0.027802   \n",
              "28457 2022-12-31 04:00:00  0.192566  0.185519  0.197306  0.192568  0.023519   \n",
              "\n",
              "            RSI      MACD       OBV       CCI       ATR       ADX       MFI  \\\n",
              "33     0.462730  0.547051  0.349256  0.465913  0.026936  0.131840  0.435173   \n",
              "34     0.491218  0.547889  0.349723  0.476396  0.025946  0.121307  0.409549   \n",
              "35     0.508651  0.548881  0.350314  0.523771  0.025513  0.119497  0.476047   \n",
              "36     0.452566  0.548987  0.349336  0.501186  0.025995  0.112142  0.452981   \n",
              "37     0.436206  0.548916  0.348484  0.459144  0.025484  0.102736  0.440309   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "28453  0.512667  0.556406  0.098259  0.596367  0.017779  0.272597  0.488741   \n",
              "28454  0.492727  0.556502  0.095665  0.554239  0.016625  0.253007  0.491220   \n",
              "28455  0.504989  0.556714  0.097975  0.548501  0.015492  0.234191  0.546242   \n",
              "28456  0.464528  0.556428  0.095506  0.515948  0.014688  0.213137  0.559573   \n",
              "28457  0.463543  0.556186  0.093417  0.457599  0.013523  0.192560  0.636551   \n",
              "\n",
              "        UP  DOWN  \n",
              "33     1.0   0.0  \n",
              "34     1.0   0.0  \n",
              "35     0.0   1.0  \n",
              "36     0.0   1.0  \n",
              "37     1.0   0.0  \n",
              "...    ...   ...  \n",
              "28453  0.0   1.0  \n",
              "28454  1.0   0.0  \n",
              "28455  0.0   1.0  \n",
              "28456  0.0   1.0  \n",
              "28457  0.0   1.0  \n",
              "\n",
              "[28425 rows x 15 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fJySHQc1vvij"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0    14385\n",
              "0.0    14040\n",
              "Name: UP, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['UP'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "assMge-pvvik"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    14388\n",
              "1.0    14037\n",
              "Name: DOWN, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['DOWN'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G30PhZn8vvik"
      },
      "source": [
        "看起來數據蠻平衡的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhAI0s7vvik"
      },
      "source": [
        "# 儲存資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5G-LQyMFvvik"
      },
      "outputs": [],
      "source": [
        "df.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGf37pdovvik"
      },
      "source": [
        "# 分割成X、y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J8yawScBvvik"
      },
      "outputs": [],
      "source": [
        "\n",
        "X,y = list(),list()\n",
        "ref_bar = 10\n",
        "\n",
        "for i in range(len(df)-ref_bar):\n",
        "    #df.iloc.values 會回傳一個numpy array\n",
        "    X.append(df.iloc[i:i+ref_bar, 1:13].values) # i to i+ref_bar-1\n",
        "    y.append(df.iloc[i+ref_bar-1, 13:].values) # i+ref_bar-1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nVAjEG8Nvvik"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.06366066, 0.05679857, 0.06863143, 0.06362536, 0.00532315,\n",
              "        0.46273012, 0.54705143, 0.34925629, 0.46591279, 0.02693599,\n",
              "        0.13183968, 0.43517312],\n",
              "       [0.0636205 , 0.05666687, 0.06848592, 0.06395496, 0.0052592 ,\n",
              "        0.49121834, 0.54788909, 0.34972341, 0.47639645, 0.02594554,\n",
              "        0.12130741, 0.40954942],\n",
              "       [0.06393785, 0.0571362 , 0.06870983, 0.06415821, 0.00665357,\n",
              "        0.50865072, 0.54888121, 0.35031437, 0.52377115, 0.02551323,\n",
              "        0.11949661, 0.4760468 ],\n",
              "       [0.06414249, 0.05730704, 0.06843876, 0.06353901, 0.01100991,\n",
              "        0.45256607, 0.54898686, 0.34933648, 0.50118569, 0.02599521,\n",
              "        0.11214169, 0.45298104],\n",
              "       [0.06354919, 0.05670197, 0.06831505, 0.06334832, 0.00959996,\n",
              "        0.43620634, 0.54891581, 0.34848381, 0.4591436 , 0.0254841 ,\n",
              "        0.10273587, 0.44030923],\n",
              "       [0.0633382 , 0.05653052, 0.06811851, 0.0636528 , 0.00966987,\n",
              "        0.46618582, 0.5493069 , 0.34934269, 0.46610558, 0.02506121,\n",
              "        0.08988118, 0.42189624],\n",
              "       [0.06365151, 0.05653052, 0.06848994, 0.06370769, 0.0069138 ,\n",
              "        0.47166741, 0.54975327, 0.34995677, 0.5145695 , 0.02392476,\n",
              "        0.07794467, 0.43154967],\n",
              "       [0.06369771, 0.05685665, 0.06843906, 0.06338057, 0.00966745,\n",
              "        0.43944453, 0.54977519, 0.34909811, 0.52205272, 0.02362162,\n",
              "        0.07377001, 0.41964071],\n",
              "       [0.0633706 , 0.05637133, 0.06803903, 0.06355544, 0.00969571,\n",
              "        0.45878838, 0.55007233, 0.34995928, 0.45765617, 0.02317353,\n",
              "        0.06367729, 0.41973873],\n",
              "       [0.06355229, 0.05674794, 0.06861643, 0.06360149, 0.00646348,\n",
              "        0.46405131, 0.55042568, 0.35053336, 0.54989148, 0.02235213,\n",
              "        0.05934713, 0.47965876]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]#這裡會出現10個array，每個array裡面有12個數字，分別是open high low close volume RSI MACD OBV CCI ATR ADX MFI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZdEmCm_Qvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.0, 0.0], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MQMldPJgvvil"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "X = torch.tensor(X, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mm5Q6Cjavvil"
      },
      "outputs": [],
      "source": [
        "y = np.array(y,dtype=np.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5nUKlKubvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7kxTYq8tvvil"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: torch.Size([28415, 10, 12]) , y shape: torch.Size([28415, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X shape: {X.shape} , y shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1bAuFUJpvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0637, 0.0568, 0.0686, 0.0636, 0.0053, 0.4627, 0.5471, 0.3493, 0.4659,\n",
              "         0.0269, 0.1318, 0.4352],\n",
              "        [0.0636, 0.0567, 0.0685, 0.0640, 0.0053, 0.4912, 0.5479, 0.3497, 0.4764,\n",
              "         0.0259, 0.1213, 0.4095],\n",
              "        [0.0639, 0.0571, 0.0687, 0.0642, 0.0067, 0.5087, 0.5489, 0.3503, 0.5238,\n",
              "         0.0255, 0.1195, 0.4760],\n",
              "        [0.0641, 0.0573, 0.0684, 0.0635, 0.0110, 0.4526, 0.5490, 0.3493, 0.5012,\n",
              "         0.0260, 0.1121, 0.4530],\n",
              "        [0.0635, 0.0567, 0.0683, 0.0633, 0.0096, 0.4362, 0.5489, 0.3485, 0.4591,\n",
              "         0.0255, 0.1027, 0.4403],\n",
              "        [0.0633, 0.0565, 0.0681, 0.0637, 0.0097, 0.4662, 0.5493, 0.3493, 0.4661,\n",
              "         0.0251, 0.0899, 0.4219],\n",
              "        [0.0637, 0.0565, 0.0685, 0.0637, 0.0069, 0.4717, 0.5498, 0.3500, 0.5146,\n",
              "         0.0239, 0.0779, 0.4315],\n",
              "        [0.0637, 0.0569, 0.0684, 0.0634, 0.0097, 0.4394, 0.5498, 0.3491, 0.5221,\n",
              "         0.0236, 0.0738, 0.4196],\n",
              "        [0.0634, 0.0564, 0.0680, 0.0636, 0.0097, 0.4588, 0.5501, 0.3500, 0.4577,\n",
              "         0.0232, 0.0637, 0.4197],\n",
              "        [0.0636, 0.0567, 0.0686, 0.0636, 0.0065, 0.4641, 0.5504, 0.3505, 0.5499,\n",
              "         0.0224, 0.0593, 0.4797]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XgiJoWzjvvil"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 0.])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDKqaaoKvvil"
      },
      "source": [
        "# 建立資料集類別\n",
        "\n",
        "- 要繼承torch.utils.data.Dataset\n",
        "- 要實作`__len__`、`__getitem__`\n",
        "- 後面要用DataLoader取用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jLDT0sbfvvim"
      },
      "outputs": [],
      "source": [
        "#用sklearn來分成train val test\n",
        "# train:val:test = 6:3:1\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CSgwdCotvvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: torch.Size([17049, 10, 12]) , y_train shape: torch.Size([17049, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape: {X_train.shape} , y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ep8tt8-avvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_test shape: torch.Size([8525, 10, 12]) , y_test shape: torch.Size([8525, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_test shape: {X_test.shape} , y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RPqE-CPfvvim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_val shape: torch.Size([2841, 10, 12]) , y_val shape: torch.Size([2841, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_val shape: {X_val.shape} , y_val shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Y0NmS_Lqvvim"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-5DjuhEyvvim"
      },
      "outputs": [],
      "source": [
        "class ValDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qHMCNEm6vvim"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ChyqvyFKvvim"
      },
      "outputs": [],
      "source": [
        "train_dataset = TrainDataset(X_train, y_train)\n",
        "val_dataset = ValDataset(X_val, y_val)\n",
        "test_dataset = TestDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib09cuxtvvim"
      },
      "source": [
        "# 建立模型\n",
        "\n",
        "- 要繼承torch.nn.Module\n",
        "- 可能要多建立不同的模型，到時候看結果再調整 -> 先讓數據流得通，再去看成績做調整。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ga66dLL8vvim"
      },
      "source": [
        "- ver1 -> CNN+MLP\n",
        "- ver2 -> CNN+LSTM+MLP\n",
        "- ver3 -> CNN+GRU+MLP\n",
        "- ver4 -> CNN+LSTM+GRU+MLP\n",
        "- ver5 -> CNN+GRU+MLP+Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "L3Da8Y1avvin"
      },
      "outputs": [],
      "source": [
        "class SelectItem(torch.nn.Module):#這是用來取出多個輸出其中一個的輸出，如果不用sequential的話，就可以不用這個\n",
        "    def __init__(self, item_index):\n",
        "        super(SelectItem, self).__init__()\n",
        "        self._name = 'selectitem'\n",
        "        self.item_index = item_index\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return inputs[self.item_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "cYU2NkZmvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver1(nn.Module): #CNN+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver1, self).__init__()\n",
        "        self.name = \"CCV-1\"\n",
        "        self.spare_layer = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 4, 3, stride=4, padding=1),\n",
        "            torch.nn.ReLU())\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 512),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 1024), \n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.ReLU())\n",
        "        self.fusion = nn.Sequential(\n",
        "            torch.nn.Linear(6, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.Softmax(dim=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.spare_layer(x)\n",
        "        x = x.T\n",
        "        x1 = self.net(x[0])\n",
        "        x2 = self.net(x[1])\n",
        "        x3 = self.net(x[2])\n",
        "        x = torch.cat((x1,x2,x3),0)\n",
        "        x = self.fusion(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qnyaDPbRvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver2(nn.Module): #CNN+LSTM+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver2, self).__init__()\n",
        "        self.name = \"CCV-2\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.LSTM(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64,2),\n",
        "            torch.nn.Softmax(dim=0))\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "BwOtPcKSvvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver3(nn.Module):#CNN+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver3, self).__init__()\n",
        "        self.name = \"CCV-3\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64,2),\n",
        "            torch.nn.ELU()\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        # print(f\"=>{F.softmax(x, dim=0)}\")\n",
        "        x = F.softmax(x, dim=0)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "AWW4C12svvin"
      },
      "outputs": [],
      "source": [
        "class crypto_classfier_ver4(nn.Module):#CNN+LSTM+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver4, self).__init__()\n",
        "        self.name = \"CCV-4\"\n",
        "        self.batch_size = 1\n",
        "        self.spare_layer = torch.nn.Conv1d(10, 2, 3, stride=3, padding=1)\n",
        "        self.gru = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64, 2))\n",
        "        self.lstm = nn.Sequential(\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 128),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.LSTM(128, 256, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(256, 512, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(512, 256, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(256, 128, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.LSTM(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(64, 2))\n",
        "        self.fusion = nn.Sequential(\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Linear(4, 16),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.Linear(16, 2),\n",
        "            torch.nn.Softmax(dim=0)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.spare_layer(x)\n",
        "        x1 , x2 = x[0], x[1]\n",
        "        x1 = x1.view(1,1,4)\n",
        "        x2 = x2.view(1,1,4)\n",
        "        out1 = self.gru(x1)\n",
        "        out2 = self.lstm(x2)\n",
        "        x = torch.cat((out1,out2),2)\n",
        "        x = self.fusion(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNwithDropout(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNwithDropout, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1 , 128),\n",
        "            nn.Linear(128, out_channels)\n",
        "        )\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Conv1d(64, 1, kernel_size=3, padding=1),\n",
        "            SelectItem(0),\n",
        "            nn.Linear(2,16),\n",
        "            nn.Linear(16,64),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64,128),\n",
        "            nn.Linear(128,2),\n",
        "            nn.ELU(),\n",
        "            nn.Softmax(dim=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output_layer(self.net(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "class crypto_classfier_ver5(nn.Module):#CNN+GRU+MLP\n",
        "    def __init__(self):\n",
        "        super(crypto_classfier_ver5, self).__init__()\n",
        "        self.name = \"CCV-5\"\n",
        "        self.net = nn.Sequential(\n",
        "            torch.nn.Conv1d(10, 20, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(20, 40, 3, stride=1, padding=1),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool1d(1, stride=1),\n",
        "            torch.nn.Conv1d(40, 1, 3, stride=1, padding=1),\n",
        "            torch.nn.Linear(12,64),\n",
        "            torch.nn.Linear(64,128),\n",
        "            torch.nn.GRU(128, 64, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.GRU(64, 32, 25),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.GRU(32, 16, 25),\n",
        "            SelectItem(0),\n",
        "            SelectItem(0),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(16,2),\n",
        "            torch.nn.Softmax(dim=0)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SS4jRXisvvin"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 12])\n",
            "torch.Size([2])\n",
            "tensor([[0.2702, 0.2641, 0.2746, 0.2708, 0.0322, 0.4950, 0.5557, 0.5632, 0.5154,\n",
            "         0.0481, 0.0735, 0.4561],\n",
            "        [0.2708, 0.2640, 0.2747, 0.2701, 0.0291, 0.4625, 0.5553, 0.5606, 0.5015,\n",
            "         0.0459, 0.0681, 0.4930],\n",
            "        [0.2701, 0.2633, 0.2741, 0.2698, 0.0300, 0.4477, 0.5545, 0.5579, 0.4507,\n",
            "         0.0438, 0.0690, 0.4103],\n",
            "        [0.2697, 0.2628, 0.2715, 0.2678, 0.0702, 0.3701, 0.5516, 0.5517, 0.2907,\n",
            "         0.0460, 0.0896, 0.4142],\n",
            "        [0.2678, 0.2618, 0.2720, 0.2681, 0.0395, 0.3869, 0.5498, 0.5552, 0.3077,\n",
            "         0.0452, 0.1087, 0.4338],\n",
            "        [0.2681, 0.2616, 0.2713, 0.2685, 0.0562, 0.4097, 0.5489, 0.5602, 0.3436,\n",
            "         0.0454, 0.1306, 0.3320],\n",
            "        [0.2685, 0.2618, 0.2723, 0.2680, 0.0394, 0.3856, 0.5476, 0.5567, 0.3889,\n",
            "         0.0440, 0.1485, 0.3319],\n",
            "        [0.2680, 0.2616, 0.2725, 0.2683, 0.0364, 0.4059, 0.5471, 0.5599, 0.4150,\n",
            "         0.0419, 0.1651, 0.3273],\n",
            "        [0.2683, 0.2615, 0.2716, 0.2677, 0.0453, 0.3768, 0.5460, 0.5559, 0.3945,\n",
            "         0.0415, 0.1867, 0.2535],\n",
            "        [0.2676, 0.2610, 0.2679, 0.2645, 0.0971, 0.2691, 0.5414, 0.5473, 0.2878,\n",
            "         0.0476, 0.2237, 0.2236]])\n",
            "tensor([1., 0.])\n"
          ]
        }
      ],
      "source": [
        "lab_tensor = train_dataset[0][0]\n",
        "lab_ans_tensor = train_dataset[0][1]\n",
        "print(lab_tensor.shape)\n",
        "print(lab_ans_tensor.shape)\n",
        "print(lab_tensor)\n",
        "print(lab_ans_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6358, 0.3642], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "lab_models = crypto_classfier_ver4()\n",
        "lab_out = lab_models(lab_tensor)\n",
        "print(lab_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [],
      "source": [
        "lab_target = torch.tensor([0.,1.])\n",
        "lab_test_ansers = [torch.tensor([1-(i*0.1),i*0.1]) for i in range(1,10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BCE loss:2.3026 ans:tensor([0.9000, 0.1000])\n",
            "CE loss:1.1711 ans:tensor([0.9000, 0.1000])\n",
            "MSE loss:0.8100 ans:tensor([0.9000, 0.1000])\n",
            "NLL loss:-0.1000 ans:tensor([0.9000, 0.1000])\n",
            "=====================================\n",
            "BCE loss:1.6094 ans:tensor([0.8000, 0.2000])\n",
            "CE loss:1.0375 ans:tensor([0.8000, 0.2000])\n",
            "MSE loss:0.6400 ans:tensor([0.8000, 0.2000])\n",
            "NLL loss:-0.2000 ans:tensor([0.8000, 0.2000])\n",
            "=====================================\n",
            "BCE loss:1.2040 ans:tensor([0.7000, 0.3000])\n",
            "CE loss:0.9130 ans:tensor([0.7000, 0.3000])\n",
            "MSE loss:0.4900 ans:tensor([0.7000, 0.3000])\n",
            "NLL loss:-0.3000 ans:tensor([0.7000, 0.3000])\n",
            "=====================================\n",
            "BCE loss:0.9163 ans:tensor([0.6000, 0.4000])\n",
            "CE loss:0.7981 ans:tensor([0.6000, 0.4000])\n",
            "MSE loss:0.3600 ans:tensor([0.6000, 0.4000])\n",
            "NLL loss:-0.4000 ans:tensor([0.6000, 0.4000])\n",
            "=====================================\n",
            "BCE loss:0.6931 ans:tensor([0.5000, 0.5000])\n",
            "CE loss:0.6931 ans:tensor([0.5000, 0.5000])\n",
            "MSE loss:0.2500 ans:tensor([0.5000, 0.5000])\n",
            "NLL loss:-0.5000 ans:tensor([0.5000, 0.5000])\n",
            "=====================================\n",
            "BCE loss:0.5108 ans:tensor([0.4000, 0.6000])\n",
            "CE loss:0.5981 ans:tensor([0.4000, 0.6000])\n",
            "MSE loss:0.1600 ans:tensor([0.4000, 0.6000])\n",
            "NLL loss:-0.6000 ans:tensor([0.4000, 0.6000])\n",
            "=====================================\n",
            "BCE loss:0.3567 ans:tensor([0.3000, 0.7000])\n",
            "CE loss:0.5130 ans:tensor([0.3000, 0.7000])\n",
            "MSE loss:0.0900 ans:tensor([0.3000, 0.7000])\n",
            "NLL loss:-0.7000 ans:tensor([0.3000, 0.7000])\n",
            "=====================================\n",
            "BCE loss:0.2231 ans:tensor([0.2000, 0.8000])\n",
            "CE loss:0.4375 ans:tensor([0.2000, 0.8000])\n",
            "MSE loss:0.0400 ans:tensor([0.2000, 0.8000])\n",
            "NLL loss:-0.8000 ans:tensor([0.2000, 0.8000])\n",
            "=====================================\n",
            "BCE loss:0.1054 ans:tensor([0.1000, 0.9000])\n",
            "CE loss:0.3711 ans:tensor([0.1000, 0.9000])\n",
            "MSE loss:0.0100 ans:tensor([0.1000, 0.9000])\n",
            "NLL loss:-0.9000 ans:tensor([0.1000, 0.9000])\n",
            "=====================================\n"
          ]
        }
      ],
      "source": [
        "for i in lab_test_ansers:\n",
        "    print(f\"BCE loss:{F.binary_cross_entropy(i, lab_target):.4f} ans:{i}\")\n",
        "    print(f\"CE loss:{F.cross_entropy(i.view(1,2), torch.tensor([1])):.4f} ans:{i}\")\n",
        "    print(f\"MSE loss:{F.mse_loss(i, lab_target):.4f} ans:{i}\")\n",
        "    print(\"=====================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "nuI6u2Psvvin"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4837, 0.5163], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.5069, 0.4931], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4360, 0.5640], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4983, 0.5017], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.4535, 0.5465], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.5649, 0.4351], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "lab_models = [crypto_classfier_ver1(), crypto_classfier_ver2(), crypto_classfier_ver3(), crypto_classfier_ver4(), crypto_classfier_ver5(), CNNwithDropout(10,2)]\n",
        "out_data = list(map(lambda x: x(lab_tensor), lab_models))\n",
        "\n",
        "for t in out_data:\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeIGq4dRvvio"
      },
      "source": [
        "## Note\n",
        "\n",
        "1) model\n",
        "    - `__init__`: define [layers](https://pytorch.org/docs/stable/nn.html)\n",
        "    - forward: forward pass -> compute prediction\n",
        "2) loss and optimizer\n",
        "    - lr: learning rate [default=0.001]\n",
        "    - momentum: momentum for optimizer [default=0.9]\n",
        "    - criterion: loss function [in torch.nn] eg.nn.BCELoss()\n",
        "    - optimizer: optimizer [in torch.optim] eg.torch.optim.SGD()\n",
        "        - eg. optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "3) training loop\n",
        "    - forward pass: compute prediction and loss\n",
        "\n",
        "        ```python\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        ```\n",
        "        \n",
        "    - backward pass: loss.backward()\n",
        "    - update weights: optimizer.step()\n",
        "    - zero the gradients: optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSv_yChTvvio"
      },
      "source": [
        "# TODO\n",
        "\n",
        "- 寫訓練方法\n",
        "    - using dataloader\n",
        "        - batch and epoch\n",
        "- 寫驗證方法\n",
        "    - using model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "BK2mvw2zvvio"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 12])\n",
            "torch.Size([1, 2])\n",
            "tensor(0.)\n",
            "torch.Size([2])\n",
            "tensor([1., 0.])\n",
            "tensor([[1., 0.]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\李軒豪\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "test_dataloader_temp = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "loss_f = nn.MSELoss()\n",
        "test_model = crypto_classfier_ver1()\n",
        "for ind,(x,y) in enumerate(test_dataloader_temp):\n",
        "    if ind == 50:\n",
        "        print(x.shape)\n",
        "        print(y.shape)\n",
        "        x = x[0]\n",
        "        y = y\n",
        "        out= test_model(x)\n",
        "        out = torch.tensor([1.,0.]) if out[0] > out[1] else torch.tensor([0.,1.])\n",
        "        loss_val = loss_f(out, y)\n",
        "        print(loss_val)\n",
        "        print(out.shape)\n",
        "        print(out)\n",
        "        print(y)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "id": "rKt9wlA3vvio"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model:  CCV-1\n",
            "loss_function:  MSELoss()\n",
            "optimizer:  <class 'torch.optim.adam.Adam'>\n",
            "lr:  0.0001\n",
            "epochs:  1\n",
            "batch_size:  1\n",
            "device:  cpu\n",
            "Train epoch:  0 i:  0 loss:  0.1943138688802719 out:  tensor([0.4408, 0.5592], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  1000 loss:  0.26273655891418457 out:  tensor([0.4874, 0.5126], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  2000 loss:  0.24515284597873688 out:  tensor([0.4951, 0.5049], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  3000 loss:  0.24141839146614075 out:  tensor([0.4913, 0.5087], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  4000 loss:  0.2535020709037781 out:  tensor([0.4965, 0.5035], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  5000 loss:  0.24800632894039154 out:  tensor([0.4980, 0.5020], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  6000 loss:  0.24912042915821075 out:  tensor([0.5009, 0.4991], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  7000 loss:  0.2490716576576233 out:  tensor([0.5009, 0.4991], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  8000 loss:  0.2506484389305115 out:  tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  9000 loss:  0.26678210496902466 out:  tensor([0.5165, 0.4835], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  10000 loss:  0.2320718914270401 out:  tensor([0.5183, 0.4817], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  11000 loss:  0.2605794072151184 out:  tensor([0.4895, 0.5105], grad_fn=<SoftmaxBackward0>) y:  tensor([1., 0.])\n",
            "Train epoch:  0 i:  12000 loss:  0.25208398699760437 out:  tensor([0.5021, 0.4979], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  13000 loss:  0.25516411662101746 out:  tensor([0.5051, 0.4949], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n",
            "Train epoch:  0 i:  14000 loss:  0.25166261196136475 out:  tensor([0.5017, 0.4983], grad_fn=<SoftmaxBackward0>) y:  tensor([0., 1.])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [357], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m out \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     36\u001b[0m loss \u001b[39m=\u001b[39m loss_function(out, y)\n\u001b[1;32m---> 37\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     38\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     39\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#setting loss function and optimizer\n",
        "loss_functions = [nn.MSELoss(), nn.BCELoss(),nn.CrossEntropyLoss()]\n",
        "optimizers = [torch.optim.Adam, torch.optim.SGD]\n",
        "models = [crypto_classfier_ver1(), crypto_classfier_ver2(), crypto_classfier_ver3(), crypto_classfier_ver4()]\n",
        "history = dict()\n",
        "lr = 0.0001\n",
        "epochs = 1\n",
        "batch_size = 1 #batch size 是一次讀取多少筆資料 我這邊只能設1 因為我們的資料是一筆一筆的\n",
        "#training\n",
        "for model in models:\n",
        "    for loss_function in loss_functions:\n",
        "        for optimizer in optimizers:\n",
        "            print(\"model: \", model.name)\n",
        "            print(\"loss_function: \", loss_function)\n",
        "            print(\"optimizer: \", optimizer)\n",
        "            print(\"lr: \", lr)\n",
        "            print(\"epochs: \", epochs)\n",
        "            print(\"batch_size: \", batch_size)\n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "            print(\"device: \", device)\n",
        "            optimizer = optimizer(model.parameters(), lr=lr)\n",
        "            train_loss = []\n",
        "            test_loss = []\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "            for epoch in range(epochs):\n",
        "                for i, (x, y) in enumerate(train_loader):\n",
        "                    model.train()\n",
        "                    x = x[0]\n",
        "                    y = y[0]\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    out = model(x)\n",
        "                    loss = loss_function(out, y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss.append(loss.item())\n",
        "                    if i % 1000 == 0:\n",
        "                        print(\"Train epoch: \", epoch, \"i: \", i, \"loss: \", loss.item(), \"out: \", out, \"y: \", y)\n",
        "                for i, (x, y) in enumerate(test_loader):\n",
        "                    model.eval()\n",
        "                    x = x[0]\n",
        "                    y = y[0]\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "                    out = model(x)\n",
        "                    loss = loss_function(out, y)\n",
        "                    test_loss.append([loss.item(), model.parameters()])\n",
        "                    if i % 1000 == 0:\n",
        "                        print(\"epoch: \", epoch, \"i: \", i, \"loss: \", loss.item())\n",
        "                if epoch % 10 == 0:\n",
        "                    print(\"epoch: \", epoch, \"train_loss: \", train_loss[-1], \"test_loss: \", test_loss[-1])\n",
        "            history[model.name + str(loss_function) + str(optimizer)] = [train_loss[-1], test_loss[-1], model.parameters()]\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
